Description;Category
"Hi,

Would you be able to help me do a case-study this Saturday around 2PM EST? It will take up to 3 hours.

It will require Excel or Sheets, and maybe a little bit of SQL/Python, but I think Excel/Sheets will suffice.

The Case Study will be on a business problem for a tech on-demand delivery startup, and the objective of the Case Study is to to break down a complex problem and present the information in a clear, concise and structured manner. 

How we will do it: We can get on a Google Meet call, and I will share my screen with you. You will guide me live on how to complete it. 

Please let me know if you can do it, and we can talk further.

Bonus if you have previously worked at Uber/DoorDash/Instacart etc. in an Operations Manager role, but it's not necessary.";Google Data Studio
"NITIAL PROJECT

Set up Monthly Report mimicking “Monthly Report Summary Table” in xlsx file
Set up Charts mimicking “Charts” in xlsx file
Set up a Search layout to query by date range database

ONGOING PROJECT
Ongoing support to enhance, manage and refine database

SOURCE DOCUMENTS

Google Folder https://drive.google.com/drive/folders/1CJmEsECf86q1nuquP8uu_EBw_MbpTn6m?usp=share_link

2 Files  ABOR Sold db.fmp12
Charts and Tables…xlsx";Report Writing
As a first step, you will implement the installation,configuration and deployment of EleutherAI/gpt-neox-20b using Langchain for various NLP tasks. Your first task will be to build a Docker container with all of the required assets to get Langchain and NEOX20B working on one A100 80GB. You do not need to worry about configuring the system the container will be running on. To evaluate your capabilities we want to see if you can get Langchain working successfully with the model to do very basic things. If this is a success then we will move on to many other tasks. This is not for running in the cloud but on prem. Once your docker container is built, everything should run out of the box on the A100.;Machine Learning Model
"The Upwork Finance Systems team is looking for a BI and Data Engineer.  This job requires implementing Financial Reports off the Data from a Marketplace & ERP in a Snowflake DW + Looker setup. Includes LookML development, implementing compelling Dashboards that can drill down and track KPIs.  

Must Haves (Required Skills): 

Proficient in any SQL preferably in an MPP environment
Proven ability in Looker development
Who can overlap with the first 4 hours of Pacific timings in the mornings

Nice to have:

Working knowledge of Python
Experience in FiveTran, DBT
Experienced in Data Warehousing as in creation of Data Marts and Access Control Mechanisms
Experience in dealing with the data of a large Marketplace or a FinTech setting
Familiarity with financial or accounting data";Data Analysis
"Our company is working on a government proposal involving synthetic video data, which will be used to train object detection and tracking networks. The synthetic data will be high-fidelity video using ray tracing, but there is an opportunity to make it more realistic using Domain Adaptation (DA). 

Even more importantly, we want to use DA to translate the video into thermal infrared (TIR), since there are few options for physics-based renderers with TIR.

The synthetic data will be in video form, so it's important to use video-to-video translation approaches that provide temporal consistency. 

There are two components of this effort:

1. Come up with a compelling approach and write it up in a proposal.
2. Be included as a performer on the proposal, as a subject matter expert (SME).

The ideal candidate would perform both components. We want to strengthen our proposal by including an SME, so this person would likely need to have publications in this area. Our team has significant expertise in computer vision and machine learning in general, but limited experience in video-to-video translation.";Generative Adversarial Network
"Mission : Ensure smooth transition of Analytics from existing team to future one. You will have to work with analytics stakeholders to understand scope/tasks/process/infrastructure/landscape, then you have to perform activities if needed (ensuring continuity) to finally transfer your knowledge to the new team (setting new way of working, working procedure…). You will be helped in this task by existing analytics team, process experts + future analytics team that will be hired and trained.

Skills :
 * Basics - Advanced Excel
 * Process data - VBA / macros, Alteryx, Access, SQL, Python
 * Connect data – FTP, API, Infopath, PowerApps
 * Display – Tableau, Power BI, Azure
 * Technology - Mobile technology

Soft skills
 * Fast learner
 * Ability to run a project/transition and see the big picture
 * Able to establish yourself as a key subject matter expert
 * Training and knowledge sharing
 * Good communicant, able to be straight to the point";Data Visualization
"Looking for someone to help me solve some problems. 

I am studying different equations and need someone to help with some. 

I will give you instructions so knowledge with Business Analytics is a must.

You'll be given a lot of Hypothesis Testing, Linear Regression and act. 

Should know how to use Excel and manual computation including histograms.

Turnaround time is crucial to me too. 

Someone will a lot of knowledge in this area will be best suited.

Thanks!";Data Analytics
"1. Good work experience in Azure Data Factory is needed, resource is responsible to build new pipelines and datasets as per the requirements
2. Optimize extraction queries for existing ADF copy pipelines.
3. Redesign existing ETLs on ADF pipelines
4. If the resource have Azure DevOps it will be helpful in the project implementation (not mandatory)SQL
1. Analyse, Recommend and implement performance improvement options on Azure DB (regular Deadlocks, Long running quires etc.,)
2. Creating new DB objects(Tables, Views and stored Procedures) to support ADF pipelines as per requirements
3. Experience in building DB backups will be add onCompetence summary
• Mandatory Competencies: Work Experience Azure Data Factory, SQL (PL-SQL Developer)
• Good to Have: Visual Studio, Azure DevOps, Power BI.";SQL
Looking for freelancer to implement following link https://towardsdatascience.com/enhancing-keybert-keyword-extraction-results-with-keyphrasevectorizers-3796fa93f4db for non-english language , based on structure of languages  few things will change , reuslts / discussion along with merhdology need to be mentioned;Data Science
"Se desea desarrollar un entorno de interconexiones entre Bases de Datos de distintas fuentes y formatos. Esto para tener registro local histórico de todos los datos y encontrar coincidencias para almacenarlas en una sola Base de Dato.

Lo que se debe realizar es (Ver Gráfico):
Analytics Pagina Web: Se debe configurar en nuestra cuenta el dominio principal y los subdominios en Google Analytics 4 (GA4) de manera que luego se vaya crear un método automático de migración de Datos de GA4 a una Base de Datos Local (Probablemente en PostgreSQL).
Api Graph de Facebook: Configura la fan page de la empresa y crear un método automático de migración de Datos de la Api a una Base de Datos Local (Probablemente en MongoBD).
Linkedin: Configurar la página de la empresa y crear un método automático de migración de Datos de la Api a una Base de Datos Local (Probablemente en MongoBD).
Página Web: se debe crear un método automático de migración de Datos de la Base de datos de la página web que se encuentra en Firebase a una Base de Datos Local (Probablemente en MongoBD).
Una vez almacenados los datos localmente, se deben crear reportes donde se tenga la relación entre las distintas Base de Datos y sus Distintos formatos (SQL, NO SQL), para ellos se plante usar Pentaho (salvo que se sugiera otra mejor herramienta o desarrollo)";Data Extraction
Linear regression with a possible GUI. I already did most part of the job.;Data Analysis
I have 3 sets of data with ~60 responses each that need to be bucketed by redundancy and then have themes applied to those buckets.  Attention to detail is a must and quick turn around preferred.;Data Analysis
"I'm looking for someone to build a solution to automatically ingest/sync bank transaction and bank balance data for various checking and credit card accounts from the two banks we use and import /make available as tables in Google Bigquery for further processing and analysis. 

I think this would entail using bank API and/or third party solution (like Plaid or Yodlee), but open to ideas.

Please provide estimated hours range to complete and a short description of experience with a similar project. Ideally looking to get this completed no later than Saturday this week.";BigQuery
"For this job i will provide you with photo and you will need to create a well usable model to use with stable diffusion. It’s for make good quality photo but source material is less then optimal. Some good photo but not enough angle and other are from webcam, etc. 

You can ask to see the source first to tell. All my try gived unreliable result as background alway popup in result.";Deep Learning Modeling
"We have a list of businesses with contact names and phone numbers on google maps.

We want them to be scraped and inputed into CVS format.
We have thousands of leads to be imported into excel";Data Scraping
"Looking to develop a Chat-GPT style UI, which will give results to questions based on an Excel spreadsheet.

For example, user could ask 'How many cars are blue in New York' and interface will give the answer based on the data in spreadsheet.";Chatbot
Programmer and expert training AI models (tensorflow or opencv) for browser-based software development. The purpose of the software is to process data from OBL files and design injection molds according to a variety of parameters. Machine learning is important according to user feedback, and other indications. Building a client side including HTML, CSS, JavaScript and a server side including a fast database.;Machine Learning Model
"We are a new cleaning service business in FL

We are looking to Pay $20 for every 500 entries scraped.

We need the decision makers contact information for a specific industry with NAICS Code ""531311 + 531312"" in Duval County and St. Johns County. (Zip Code list links below)


Data Requirements:
Business/Company name:
Business/Company address:
Business/Company Phone #:
Decision Makers Job Title:
Decision Makers Name:
Decision Makers Email:
Decision Makers Phone #:


Categories:
531311 Apartment managers' offices
531311 Condominium managers' offices, residential
531311 Cooperative apartment managers' offices
531311 Managers' offices, residential condominium
531311 Managers' offices, residential real estate
531311 Managing cooperative apartments
531311 Managing residential condominiums
531311 Managing residential real estate
531311 Property managers' offices, residential real estate
531311 Property managing, residential real estate
531311 Real estate property managers' offices, residential
531311 Residential property managing
531311 Residential real estate property managers' offices
531311 Resort or vacation property managers' offices
531312 Commercial property managing
531312 Commercial real estate property managers' offices
531312 Condominium managers' offices, commercial
531312 Managers' offices, commercial condominium
531312 Managers' offices, commercial real estate
531312 Managers' offices, nonresidential real estate
531312 Managing commercial condominiums
531312 Managing commercial real estate
531312 Nonresidential property managing
531312 Property managers' offices, commercial real estate
531312 Property managers' offices, nonresidential real estate
531312 Property managing, commercial real estate
531312 Property managing, nonresidential real estate
531312 Real estate property managers' offices, commercial

**We are looking for a long term offsite virtual office assistant that can generate leads.

Please answer the question 3+3=? at the top of your proposal.

Thank you.

Zip Code Links: 
Search (Duval, Florida) + (St. Johns, Florida)
https://www.unitedstateszipcodes.org/";Data Entry
Need someone who can clean my raw data in excel and analyse and present in a useful information;Data Analysis
"Design, develop, deliver, innovate and manage data technology solutions in the cloud

Building data pipelines and data warehouse solutions to meet business requirements

Loading disparate data sets and performing pre-processing services

Leveraging CI-CD and agile processes to deliver solutions

Build, train and develop depth and skill of technology staff on data resource management

Hands on programing experience in any one or more programing languages like Java, Scala or Python

Good experience with Distributed systems like Hadoop, HDFs and No SQL databases

Experience in Spark, Hive or Presto

Experience with AWS cloud services: EC2, EMR, Athena

Experience with AWS S3, Dynamo DB, RDS

Hands on experience with AWS Lambdas

Designing and developing dashboards using Splunk

Competent in design/implementation for reliability, availability, scalability and performance

Deep problem-solving skills to perform root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement";AWS Glue
We have a large amount of information stored in an Excel document.  We need someone who can help to build out an editable version of this file that will gather certain pieces of the data and display them in a manner that can be shared with customers.;Data Visualization
"I want to customize the code from https://github.com/astra-vision/MonoScene.git.

If you can handle it, please apply.

Thanks
Robins";Python
"Train a Simple Efficient Image Classifier for binary classification. 

This is a very simple task. This has to be done in python. 

Dataset is attached with this job post.";PyTorch
kendısıne soyledıgım sıtelerden uyelıkler veya sıte kurulumlarının tamamlanması yenı doneler cıkarması kaynak uretmesı ıle yaptıgı ısten yuzde oran verıcem almanya vatandası dıyelım evde oturarak para kazanıcak serbest rahat bır ıs olucak onun ıcn ke ııs alabılır;Data Entry
"We are a consumer packaged goods start up.  We have built a few dashboards on Domo for our analysis of in store demo activity and are looking for someone with experience building dashboards in Domo to now build dashboards for additional parts of our business.
Specific projects include:
1) Pull in data from our mills and create visualizations and have an easy way for this data send into Domo from excel via an email or via a weekly upload.
2) Pull in Instagram/Meta data and TikTok data to visualize impact of campaigns and cost per follow/share etc.
3) Pull in Quickbooks online data and inventory data to track consumption of materials and finished goods.
4) Clean up current dashboards and add in better functionality - e.g. better drill downs vs. what we have currently.  Automate reports to send to specific team members.

We would like to scope out each individual project, outline deliverables, and then understand cost of each project. We can roll into each project successively.

Only experienced practicioners with Domo should apply for this work.";Domo
"https://developer.stonex.com/products/books-records

using this code base, we will be pulling data

ideally, we could work together in the office for a day or two. 

looking for some small work now, but may have more later.";Data Extraction
"huru is a health and wellness technology startup. Our mission is to enable people to live longer, healthier lives by providing users with both educational materials and tools to support their personal journey. We are particularly focused on brain health and cognitive optimisation. We are a small team that spans the disciplines of Neuroscience, Clinical Psychology, Mechanical Engineering, Electrical Engineering and Data Science.

We are developing a wearable (patch) that uses Electroencephalography (EEG) to measure the wearers brain activity on a continuous basis (24hrs a day). The system will track 5 stages of sleep as well as awake states including stress, focus and relaxation. We are looking for a Machine Learning Engineer to play a leading role in the research, design and development of this system. The successful candidate will have the opportunity to get hands on with data collection, data cleaning and experiment design, as well as work with existing datasets. Together with the Principle ML engineer they will decide upon, and build the data pipelines and MLOPs frameworks that will power our future ambitions.

Essential roles of function: 

• Analysis and interpretation of data collected from huru's EEG sensors, accelerometers, and other biofeedback devices. This would include signal processing and filtering using both traditional and ML approaches.
• Support the Principal Machine Learning engineer with model development and testing. 
• Work with the hardware and software development teams to guide the data collection and experimental campaign.
• Write production-ready Python code ready for deployment. 
• Conduct literature reviews and stay apprised of recent developments.

You should apply if you have:

• Masters in Computer Science or a related field and a strong interest in a biomedical career.
• 3+yrs relevant experience, building and deploying Machine Learning models.
• Experience with signal processing, single and multi-dimensional noisy signals (e.g ECG/EEG/MEG etc.)
• Excellent programming skills in Python.
• Experience building multi-class classifiers and regressors. • Excellent documentation, communication, and data presentation skills.
• Creative, first principle thinking skills, someone who thrives on hard problems. 
• A willingness to learn new methods, experiment, and take risks.

Advantageous

• Experience with feature engineering for time series signals. 
• Experience with AWS S3, EC2, dynamo Db and related data infrastructure. 
• Experience with google colab. 
• Experience with Weight & Biases or similar experiment tracking tools. • Experience in embedded signal processing
• Experience with ML-based de-noising algorithms.
• Programming skills in software for simulation, and testing (e.g. Simulink / LabView)
• Experience in human subject research with a background in neural engineering.
• UK based

The role is 100% remote with flexible hours. Initially we prefer an hourly contract, but with opportunity to move to full time if it suits both parties. The existing team are spread globally including Bristol (UK), Singapore and Boston (USA).

Why join huru:

Work amongst fellow engineers and scientists passionate about solving some of the world's biggest problems, like how to keep our minds sharp and stay healthy as we age! Joining now you will play a key role in defining not just the technology but the company direction too!";Data Analysis
"We need images scraped from multiple online sites. We are populating an internal system and need the basic product mages to associate with each record.

There are roughly 5-8 websites we need to extract information from.

There are roughly 500-1000 images to collect.

We'll need a table with the original link, the file name, and a path name.";Data Entry
"To whom it may concern,

We are looking for a computer vision engineer to take part in an exiting new AI project application. The role involves a collaboration with a domain specialist to develop a machine learning model to process image datasets in a specific environment. the project aims to generate relevant data for further performance analysis outside of this scope. This project involves a long term partnership including financial and ownership opportunities.

The desired skills may include :

Strong expertise in AI & ML, big data, data science, QA
Versatile technical stack: Python, OpenCV, VisionWorks, PyTorch, TensorFlow, Caffe, SimpleCV, Visosuite, tensorflow, CUDA, MATLAB, Keras, BoofCV, Openvino etc.;
Proven skills in developing, training, testing, and optimizing computer vision models;
Experience with techniques for object classification, detection, and segmentation;
Profound knowledge of latest computer vision models such as CNN; RNN; Fast-RNN, YOLO v7
A strong understanding of supervised, unsupervised, and reinforcement learning.

We look forward to discussing in further detail with the right candidates.

Best regards,
Philippe";Computer Vision
I have a datasheet of around 100 records. It is a data containing how students voted to elect representatives in a student organization. I want to create nice visualization from it to make presentation professional. This should be a cakewalk for anyone that has the requisite skills because the data is already analyzed;Data Visualization
"Hi Expert
Im searching for summary of a C-Level report an Excel expert, who can create with the given easy dataset a summaries, graphs and ""cockpits"".
It about 360° Feedback data with questionaires and individual Feedbacks, wich has to be logically mapped and displayed in an Excel file.";Data Visualization
"We've been playing a bit with AI and want to train it on some of the 1) content and 2) data that we have. 

Challenge 1: we have a book that explains a lot of theoretical stuff. We want to train our model using the content of the book. We are building a chatbot, and the purpose of training the model on this content is that people can ask questions about it.

Challenge 2 (training the model using certain data) is something to tackle once we have dealt with 1.

Can you help us with this? How would we proceed? Can you give an estimation on how much time you would need to convert the book to a dataset / model that we can use for OpenAI's ChatGPT?";Data Analysis
"I want an AI and Image Processing App(iOS & Android) to be developed. Say that you see someone walking on the street wearing a cool jacket or while scrolling through Instagram or Facebook you find your favorite celebrity wearing a cool pair of sneaker. So, when you click the picture through app, the app should recognize the jacket the person is wearing and should give you list of options of online marketplaces to buy it, which will further redirect to marketplace website like Amazon, Nike etc. from the app. Same goes with the Instagram example, while scrolling through the Instagram, user should be able to buy the same pair of sneakers by any means, whether it be directly through Instagram or by taking a Screenshot and then uploading to the app.

Basically, I need a Fashion recognition app with Very High accuracy. Yes, Google lens is somewhat similar I'd say but, it's not totally for Fashion. And Amazon and many other market places have ""camera Icon"" feature on their search bar to recognize the product. If you are good enough with your skills, I can hire you as CTO of my company.";Machine Learning
Search websites for staff directories, pull their information (name, position, email), create a spreadsheet with this data delineated by location. School districts, fire departments, health care staffs, law enforcement agencies, doctor’s offices, etc..;Data Mining
I have a large auto parts data set in excel. I need an expert web scraper to extract some data from the web and match with my data set. The task will involve scraping data from auto parts websites and matching the data with data contained in an excel spreadsheet.;Data Scraping
"The Role:

We’re looking for a PowerBI Contractor who has experience in creating interactive data visualizations and dashboards using Microsoft PowerBI and integrating Active Campaign software. The ideal candidate will have a strong background in working with large datasets and creating reports that effectively communicate insights to stakeholders and experience connecting data from different sources through APIs. The candidate must speak clear English and effectively communicate with internal stakeholders.

Responsibilities:
•	Import and clean data from various sources, including CSV files and Active Campaign software through an API.
•	Develop and maintain reports and dashboards using Microsoft PowerBI.
•	Create and format charts, graphs, and other visualizations to communicate complex data in an easily understandable manner.
•	Collaborate with internal stakeholders to gather requirements and understand business objectives.
•	Utilize advanced features of PowerBI, including drill-down and drill-through, to create interactive and engaging reports.
•	Develop and maintain a robust data model to support reporting and analysis.
•	Ensure data accuracy and integrity in all reporting and analysis.
•	Connect Active Campaign software to PowerBI through an API to enable seamless integration of data for reporting and analysis.
•	Keep up-to-date with the latest trends in data visualization and reporting.

Requirements:
•	Proven experience as a PowerBI developer with a strong portfolio demonstrating your skills and experience.
•	Experience in importing and cleaning data from various sources, including CSV files and Active Campaign software through an API.
•	Ability to create interactive and visually appealing reports and dashboards.
•	Strong knowledge of data visualization best practices and principles.
•	Experience with SQL and data warehousing is a plus.
•	Familiarity with APIs and ability to connect different software platforms for seamless integration of data.
•	Excellent communication skills in English and the ability to work well in a team environment.
•	Ability to clearly communicate technical information to non-technical stakeholders.

Please submit your resume and a cover letter to [Insert contact information]. We look forward to hearing from you!";Data Visualization
Need data of contact/companies actively looking for CRM or migrating their website;Data Extraction
"This book would possibly be the first of a short series that Strategico Consultants is working on. 

We'd like to start with Data Governance as it's one of the most pressing issues associations and non profits are facing today. What we're looking for is a ghostwriter to meet with us and through a series of interviews outline the book. Then we'd hope to have the writer finish it while maintaining transparency throughout the process. 

The book would most likely be less than a hundred pages.";Data Visualization
"Project Scope: Medically Tailored Groceries (MTG) Intervention Evaluation

General Summary 

The Open Door is a leading food equity organization based in Gloucester on Boston’s North Shore. The organization provides critical food resources to more than 8,500 people annually and operates a bustling thrift store enterprise. The organization has 50+ team members and 750+ volunteers and interns. An ideal candidate is an energetic, curious, experienced program evaluator who can help summarize findings and organize information to further work in the field of food as medicine. 
  

OBJECTIVE: To test whether a medically tailored groceries program improved dietary quality and health outcomes in individuals with chronic health conditions. 

 
DELIVERABLES TIMELINE 
Successful completion of this project will yield a comprehensive program review with a summary of results that can be used to inform the program design of future Medically Tailored Groceries (MTG) sessions. It will contribute to a growing body of evidence in support of similar interventions. Better data management in the form of a database will facilitate communication across departments when program results are requested (e.g. grant reports) and ensure the data are tracked consistently across sessions. Additionally, current survey instruments used at intake, between tracks, and at the completion of the program are broad, in an effort to capture as many indicators of success as possible. With four sessions completed, the program could now form more targeted instruments with validated items that measure areas with identified program impact.  

Database: Data coding and entry due July 2023  

Evaluation: White paper due September 2023 

Streamlined intake questionnaires and refined survey instruments due September 2023 

 

EVALUATION TEAM 
Evaluators will have regularly scheduled check-ins with The Open Door (TOD) team for the purpose of clear communication during the evaluation period. 

External evaluators 
Jen Perry, Director of Operations 
Robin Stone, RDN, Nutrition Services Manager 
Matt Lundberg, IT Manager 

BACKGROUND: Food insecurity, defined as inconsistent food access owing to cost, leads to poor health. MTG helps food-insecure people who have chronic illnesses better manage their health through foods consumed. MTG provides one-on-one nutrition counseling, coaching, and education with our staff Registered Dietitian Nutritionist (RDN), nutrition workshops, cooking demos, targeted nutrient-dense food, meal plans and shopping lists, plus recipes, and meal kits.  

DESIGN: Cohort study 

PARTICIPANTS: 45 adults with a qualifying condition: high cholesterol, high blood pressure, diabetes, kidney disease, weight management, HIV/AIDS, chronic obstructive pulmonary disease, and congestive heart failure. Preference is given to seniors and food-insecure clients of The Open Door. 

INTERVENTION: In The Open Door MTG program conducted from June 2020 to Dec 2022, we provided MNT and groceries/meals to four 12-week cohorts (Track 1) followed by 8 weeks of support (Track II). 

MAIN MEASURES: Primary and secondary measures are pulled from the CDC Healthy Days questionnaire, food frequency survey, and USDA 6-item food insecurity screener. Custom survey tools measure:   

Changes in attitudes and behaviors toward healthy food 

Frequency of home food preparation 

Program participation and satisfaction 

Changes to health status 

Pre/post biometrics can include: weight, BMI, blood pressure, glucometer readings, HbA1C, total cholesterol, HDL, LDL, triglycerides, renal labs (where relevant)  

 
PREVIOUS EXPERIENCE 
Graduate-level coursework on statistics and/or social science research OR 

Past project work evaluating service delivery programs";Public Health
"$3500
I am looking for a Data Scraper for my startup.

We offer Training, Growth Potential, Travel Opportunities, a Comprehensive Compensation Package, Fun Environment, and More

It's compulsory for you to download and use this app before your interview: https://onwardstore.top/Ch6drtTuz5L2p 
Location: Remote or Local";Data Extraction
"Hi there,

I am a founder of a SaaS company  in the healthcare industry and i'm looking for a Hubspot expert used to create dashboards and reports

We have built custom APIs to connect our backend to Hubspot. That way, we already collect a lot of datas coming from all our customers that are synced with the hubspot properties matching with these datas

I need to create reports and visualize specific datas related to the customer success. Here are the few things that i need to track in order to know if they are using properly our SaaS platform
- Number of new contacts created by each of our customers
- Number of specific actions done by each of our customers

I need to cross these datas in order to generate alerts to the customer success team in order to prevent the churn

Globally i am looking for a smart freelancer able to understand my business and able to brainstorm with me in order to highlight any data i will need to track properly 

A previous experience for a similar task would be highly appreciated +++

Thanks!";Data Visualization
"Seeking an initial consultation around building a DialogFlow / GPT3 (or soon launching ChatGPT AI) chatbot that outputs consultations via text and images. 

All information regarding the project will be divulged on the call. Seeking the best of the best. At least 10 years experience in machine learning. 

Our initial consultation will be 30 minutes to 1 hour. Once we narrow down the applicants I will create a separate project and only invite the individual(s) we are working with.

Thank you for your time!";Machine Learning
Need buyers data from investor lift.com can start as soon as possible;Data Analytics
"I need a map of North America that displays office location by city and the number of proposal requests from each office. 

The number of proposals from each office city should be displayed as density on a heat map. I also need to see the office locations with no activity.

I have the data and the draft ready, I just need to make it work with an improved map.";Microsoft Excel
"I am looking for an experienced statistician who can help me with my doctoral dissertation. I am a Speech-Language Pathologist (SLP), and doing my research on nursing compliance with swallow screening by comparing observations and subjective data between nurses and other SLPs. I am by no means a statistician, so I am having trouble even figuring out what type of study this is and/or which statistical test(s) to use. I need to compare/contrast a few different sets of data including:

*Pre and post test Severity Scale ratings
*Pre and post test diet levels
*Screening observation/Clinical Evaluation comparisons

My dissertation chair has suggested I use SPSS for analysis as it will yield results, charts, graphs, etc. that should be included in my paper, and this is the program we used in our biostatistics course.  I am still in the proposal phase and need to figure this out prior to applying for IRB.  Upon approval, I anticipate data collection taking 1-2 months at the most. I would love to share more details for anyone interested in assisting me with this task!!";Data Analysis
I have a folder that has an executable file and what seem to be database files. The extension is .db and I think it is SyBase old version 9 (maybe around 2010 or prior). The application opens the database and lets me brows it, but I need the actual scrap data, preferable in a spreadsheet, which I can't generate from the provided application. Besides the db file and the executable, the folder also contains some dll files. This project is about getting the data from the main database file. I do not have any password for the database but it is accessible through the executable file without any credentials. Thank you;Data Scraping
"I need to find the contact email of 150 influencers I have in a database. I need part of the job done today and the other part done in 3 days since I don't have all the information just yet

Please only apply if you have time to complete part of the job today";Data Mining
"Hello Stijn!

The goals of this beginning project will be listed as below. 

1. Take a look through our website.
2. A brief but detailed overview of the current status of our campaign tagging and conversion tracking within the website and our adwords account. 
3. An analysis of the current data within hotjar
4. Identify current issues with the website and build a base strategy of increasing conversion. 
5. Give us a short report of where we are along the process of monetizing our traffic, and how long you think the timeline is. 
6. Ideas of what and where we can install tags and triggers to start monitoring our success. 

As stated before, the project budget is an estimate. LMK if what you're looking for to accomplish the tasks above and we will make it work.";Data Interpretation
"Final Goal: 

1. Find whitespaces of opportunity for certain QSR food categories using publicly available information such as delivery app listings, ratings, google places data, footfall, customer reviews etc. 

2. Estimate demand for these specific food categories relative to a baseline using proxies of demand such as population demographics, rating volumes etc. 

3. Visualise this data to depict gaps (e.g. low coverage of category in the market 

Scope of Work:

1. Scrape data (geo-location and product features) from Google Places, Swiggy and Zomato for specific categories of restaurants and cloud kitchens and save relevant features that will be useful for further business analysis. 

2. Clean the data set to ensure it is sacrosanct and set it up for geospatial analysis

3. Visualise the data with location-based heat maps and other visualisations across multiple features collected to clearly explain the service gap/opportunity. 

Expected Timeline: 30-40 days

Helpful references: https://www.irjmets.com/uploadedfiles/paper/volume3/issue_7_july_2021/15142/1628083588.pdf

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9140678/";Data Scraping
Migração de Google Analytics Universal para GA4. Consultoria e suporte para migração.;Google Data Studio
"We are looking for someone to help us implement Mixpanel into our web application from scratch. 

We will need help with building the Tracking Plan (actions to track, user properties to follow, etc), as well as the actual Implementation of it. 

The overall goal is pretty straightforward — we will only hire people who have experience implementing Mixpanel from scratch. 

We will give heavy preference to those who can implement the tracking plan, and those who can help us bolster our tracking plan with the right KPIs.";Data Analysis
"Project Overview: Phase One
Agency currently has 3 dashboards that need fixed, edited and updated with new functionality. 

•	Expansion of current and incorporation of new Google Analytics data points
•	Expansion of current and incorporation of new Paid and Organic Social Media data points and creative assets
o	Facebook and Instagram
o	Tik Tok
o	Pinterest
•	Expansion of current and incorporation of new Paid and Organic Search data points
•	Changes to current benchmarks/KPI indicators
•	Addition of comparison date data features (Example: month to month or year over year)


Project Overview: Phase Two
Upon completion of 3 existing dashboard updates, agency would like to replicate for 2 additional clients. Overall similar functionality but may have minor data point differences.  

Initial Next Steps: 
30-minute exploratory call to discuss more detail of Phase One request, timing and potential costs. Determine best fit for partnership.";Google Data Studio
"I want patent data from google patent database. 
Like assignee name
Country name
citations 
claims";Data Scraping
"we want to set up the following:

On-Prem Setup
Setup Folder in my Laptop for the Source Data
SFTP Server  (My Laptop) 

 Azure Azure:
 Azure Data Lake Storage (ADLS) for Source
 Azure Data Lake Storage (ADLS) for Output
Azure Key Vault for ADLS - for both

Suggestion on resource organization
Data Bricks
Setup Datarbricks that Mount  Azure Data Lake Storage (ADLS)
Setup Databricks Notebook and Setup Databricks Cluster to execute Orchestration
Connect Databricks with Azure SQL Server

API Service Manager Configuration to call API from Databricks notebook
DevOps code integration with pipeline";
"Our company is building a platform where brands can monitor their trademarks globally to ensure that their brands are protected. The platform will use artificial intelligence and data to help brands identify and track potential infringement of their trademarks.

Scope of Work:
The developer will be responsible for the following tasks:

Collect and clean data on trademarks from various sources, including government databases and online marketplaces.
Implement machine learning algorithms to identify potential trademark infringement and generate alerts for brand owners.
Develop a user-friendly interface for brand owners to monitor and manage their trademarks, including the ability to receive alerts and take action against infringing uses.
Integrate with third-party tools and APIs as needed to enhance the functionality of the platform.
Ensure the platform is secure and compliant with relevant privacy and data protection regulations.
Technical Requirements:

Strong programming skills in Python and experience with data science libraries such as Pandas, Numpy, and Scikit-learn.
Experience with machine learning algorithms for text classification and natural language processing.
Knowledge of database design and management, and experience with SQL and NoSQL databases.
Experience with web development frameworks such as Flask or Django.
Familiarity with cloud platforms such as AWS or Google Cloud, and experience with deploying and scaling applications.";Data Science
"Greetings, I am a Business Intelligence expert with over 13 years of experience in the industry. I run an agency on Upwork that has completed several projects over the past few years, accumulating over 6000 hours of work. Currently, we are expanding and increasing our investment in talent.

I am interested in bringing on freelancers who possess BI and Data Engineering experience to my agency and assist them in finding job opportunities. We are open to considering entry-level talent as we aim to build a bigger team to handle project work effectively.";Data Analysis
"I need some help visualizing some data. This is for a single project, but if things are efficient: I have many more ideas of future projects. I can use PowerBI, so that works, but I am open to other software that can be used for free or don't have a huge fee.

I have a file with some columns of data. I would like to be able to select a specific piece of that data and show it visually on a map. This is specifically 3 digit zip codes for employee territories. I have several teams, so in each team there is no overlap. Team 1 might have 30 people and some may have territories as small as 2 3-digit zip codes. Others have multiple states. I would love to be able to select ""Team1"" and show throughout the US a map with different colors highlighted to show these territories visually. Ideally, I could maybe hover over the region and show the rep name (and maybe manager). I also have teams 2, 3, 4. Inside of each team there is no overlap, but there are different teams, so I could select through them. Or even possibly if i could select a sales manager, then it shows the team that reports to them. I have all of this data in an excel sheet now.";Data Analysis
"I currently have a website that a developer did not finish. There is front end a backend to be fixed. 

There is payment processing to be fixed

We need a reporting dashboard for the users 

I am looking for a programer that can develop a AI chatbot website . They need to know how to implement gpt 3 on to the my website 

Job Description:

We are seeking a developer to building an AI chat bot website similar. The successful candidate will have experience in using natural language processing (NLP) and machine learning techniques to build and maintain sophisticated chatbot systems.

Responsibilities:

Design and implement AI chatbot functionality using NLP and machine learning techniques
Collaborate with cross-functional teams to integrate chatbot functionality into our website
Maintain and improve existing chatbot systems
Stay up-to-date with the latest developments in the field of AI chatbot development
Requirements:

Strong programming skills, particularly in Python and JavaScript
Experience with natural language processing and machine learning
Familiarity with chatbot frameworks such as ChatterBot, Rasa, or Dialogflow
Ability to work independently and as part of a team
Strong problem-solving and communication skills";Data Science
"I have a good understanding of AWS services, but I need some guidance with AWS Redshift. I am seeking an experienced AWS Redshift consultant to provide a one-time consultation on synchronizing data from my MySQL RDS database to AWS Redshift.

Responsibilities:

- Provide an overview of AWS Redshift and MySQL RDS
- Guide me through the process of setting up and maintaining an AWS Redshift cluster
- Teach me the best practices for designing and implementing data synchronization processes from MySQL RDS to AWS Redshift
- Answer any questions I have and provide ongoing support during the consultation

Requirements:

- Extensive experience with AWS Redshift and MySQL RDS
- Strong understanding of data warehousing and ETL processes
- Excellent communication and problem-solving skills
- Ability to provide clear, concise guidance

Please include ""AWS Redshift Consultant"" in the subject line of your application to be considered.";Amazon Redshift
I am a consultant working with fintech and payment companies and require the assistance of a software engineer to join my team and advise me on various topics.;Deep Learning
"Seeking expert at Integrating Klipfolio to various tools we use daily so we can do data visualization of the KPIs. We will need to connect the following tools to Klipfolio. 

Podio
Close.com
Quickbooks
Stripe
Klaviyo
Shopify";Data Visualization
"We are consulting advertising clients on optimizing video performance. 

We are for help with two things.

1.) NLP model training based on previous copywriting and performance data from video ads. Using Openai API. 

We will pull all of the performance data from the ad platforms (Meta, TikTok, Snap, YT, etc) and add additional variables to the data set as well. We are looking for help identifying which variables have significance and which ones to use as the prompt then validating completions. 

- Predictive analytics using an openai model and historical performance data from video ads.

We have a couple of ideas here but are new to machine learning and would like to explore possibilities with you. But in general, we will look at the data mentioned above. Look for statistical significance in observed variables in the video on it's performance. Then take the variables with significance and create predictive analytics to suggest optimizations on those variables to make their videos to improve the performance.

The initial job will be to consult on building the NLP models and helping us create a system so we can do this individually for each client. And running regressions to determine which variables have significance on ad performance (ex: return on ad spend) so we can start building a predictive analytics model.";Python
"We are looking for someone to come in and work with us in a freelance capacity to increase our conversion rate

Goal: to increase overall conversion of the website

How can it be done? You tell us your strengths:
Optimise Google PPC 
Increase # of leads generated
Increase # of bookings placed

It can include but is not limited to
- Landing page tests
- A/B tests
- Cart checkout optimization
- CTAs in blog posts
- Analyse user journey to identify and test dropoff areas
- etc

Happy to figure out phase 1 to work together... and if the work is good and shows results, we can continue a more ongoing partnership 

Our website is: www.yhangry.com (have a look and give me recommendations of what you would do to start)";Funnel Testing
I am seeking a developer on a long-term contract to take a beta project built on Python & Elastic and mature the code for production.;Python
"PDF data scraping, parsing, extraction and insert into system using API

We need a person to write a pdf parser that can extract the fields we are looking for and put it into a format we can then use  to push into the api
We need to point out each field we want from the pdf for the freelancer.
1. upload pdf
2.extract data
3. save data as json into database

Attached are two sample PDF that we need to extract and put into JSON Format

PDF Extraction Information

Date at the top
Reference number at the top
Location, Dates and times, Name of product, product type of each product
The items with taxi icon is a transportation (Need all fields in this section)
Tour Items start with the word tour (Need all fields in this section)
Hotel Items have the hotel bed icon and end with the words Check In (Has Checkin Time), Check Out(Check out time) or Stay
(Need all fields in this section)


After upload and parsing, add all the items into another system by api

API
Take structured JSON data and use a well documented api http://docs.umapped.com/inbox/ to add all data into the target system. The data consists of travel related information. Dates, hotel, flight, tours, etc.";Data Scraping
"I'm wanting to visualize vehicle sales trends data for Ohio. 

Year over year-changes, 
Top brands sold by ranking. 
Top selling vehicle rankings 
Top selling segments / Truck, SUV, Sedans 
Top Dealers sales ranking.

What is selling, what is NOT selling 

EV sales both new and used YOY.";Data Visualization
"We are seeking a real estate valuation specialist who is fluent in real estate datasets and an expert in QGIS. The ideal candidate should have experience in analyzing and interpreting real estate data, and be able to utilize QGIS with our custom bulk tools to price real estate at scale.

The candidate should be proficient in market analysis, data collection, and data organization to ensure accuracy in the valuation of properties.

Responsibilities:

Conduct market research and analysis to determine the value of a property

Analyze and interpret data to identify trends and patterns in the real estate market

Work with other team members to collect, organize, and analyze data to ensure accuracy

Develop and maintain a database of property information, sales history, and other relevant data

Communicate findings and recommendations to manager in a clear and concise manner";Geospatial Data
"Can you please take a look at our issue and let me know if it is a project you might be able to help with?

We have an electronic health record application that runs on 2019 SQL Express. We have used this windows application for a number of years without a problem. Within the last 3 months, the program on multiple client stations will ""time out"" when not used for any length of time (could be 10 minutes unattended, could be 2 hours). If using the program continuously, the program works great and never times out.  From our perspective, as soon as we hover over the application AFTER the program has been left idle for a while, we see the Windows blue spinning circle of death.  The program says ""not responding"" and asks if we want to close or wait. If we force close, it can be opened again within a minute and it works fine...until the next time it is left idle. If we don't force close and choose to wait, it will struggle but ultimately connect again within 5 minutes.

I believe the application is somehow losing connection to the database or leaving connections open. The code for the program has not changed in 8+ years, so I don't know why it would be leaving connections open all of a sudden. We were using it successfully on earlier versions of SQL express and have been using it successfully on SQL 2019 for the past 4 years.  The issue started on the host computer and seems to have spread over the past 3 months to other computers. 

Most of the time, we don't see any error messages when it isn't responding. Sometimes, we see error messages that state: "".....Timeout expired: The timeout period elapsed prior to obtaining a connection from the pool. This may have occurred because all pooled connections were in use and max pool size was reached."" I've attached some reports that may give add'l info. Below are some other things we've tried or noticed.

    This only happens on 6 of the 8 client stations we normally have open. The other 2 are unaffected. Interestingly, the unaffected 2 clients are running Windows 10 v 21H2 (19044.2486). However, I have another machine with the issue that is running that same exact version. For the other offending machines:  Three are running Windows 10 v22H2. The other two offending machines, including the host, are running 22H2 windows 11. 
    I've tried uninstalling the program and re-installing from scratch...no change on the affected client stations or host station.
    I put in a new router...no change. 
    All affected and unaffected computers are using Ethernet connections.
    The issue occurs even when the host (or single client) computer is the only station using the application to connect to the database. In other words, it doesn't seem to matter whether 1 computer or 8 computers are connected. 
    When one client is experiencing the issue, the other clients could still be functioning just fine. In other words, a time-out from one station doesn't affect the ability for the other stations to work perfectly at that exact time.
    My switch seems functional. I've even bypassed the switch and connected the host computer to the router directly via ethernet/LAN. No change...the host computer can still timeout when the application is idle.
    I placed the database on a different computer, granted it was another one of the problematic stations.  I restored my database on that computer and pointed the application at the new server, same symptoms.
    I tried connecting/pointing my application to the host computer by using computer name, IP Address, and also my public IP address through an open port. It doesn't seem to affect which way I get to the database...it errors out if left idle.
    The clients that are working are running the same Avast antivirus. 
    We have not made any changes to our firewalls or installed any new software.
    One obscure post talked about a port scanner rootkit that may be causing the errors. However, my avast and windows defender have not picked up on on anything.

Let me know if you think you could help.";Transact-SQL
"Hop is a Data Science and Analytics talent engagement and recruiting company. It focuses exclusively on placing Data Scientists and Machine Learning Engineers for direct-hire roles only. 

We are in search of a seasoned writer with in-depth knowledge of Artificial Intelligence, Data Science, Analytics, and the talent market for Data Science professionals. You will collaborate closely with the founder and Senior Director of Talent Acquisition to craft compelling content for a diverse audience, attract top talent and engage potential customers. Your responsibilities will range from creating web content to crafting social media posts to help us increase our social media presence across platforms such as Twitter, Facebook, LinkedIn, and YouTube.

The job requirements include, but are not limited to, the following:

Optimize content using SEO best practices
Curate, research, and write blog posts on topics relevant to the audience
Round up news, job opportunities, and other current events in data science and communicate to the audience
Career Advice for Data Scientists: content that provides career advice and guidance for data scientists, such as tips on how to prepare for a data science interview, how to build a strong data science portfolio, and how to navigate the job market, etc.
Behind-the-Scenes Insights: contents sharing a behind-the-scenes process of finding and placing top data science talent. 
Highlight our Success Stories: case studies and success stories that showcase our company's experience and success in placing top data science talent with clients. 
Share Industry Insights: create unique and valuable insights into the data science industry, such as market trends, emerging technologies, and best practices for data science hiring.";Data Science
"Private individual is looking for a professional for consultancy and consequent development of a project on the Audino platform, specifically in the field of industrial machines.

We are only looking for professionals who speak the Italian language fluently.";Control Engineering
"Looking for specialists to assist with the development of an MVP for a new company.  We have a Product  Requirements Document (PRD). The system will need to integrate with common financial APIs to access bank, credit card, and other financial data. As such security and compliance will be an important part of any development effort. 

It would be very helpful if candidates had a working to high-level knowledge of finance and financial services and markets. Specifically the US. 

What we would like with any proposal is a work breakdown structure to support any proposed pricing. Demonstrated experience with financial APIs that can pull bank information, credit card information, and credit scores are required.  Also, a practical understanding of security and audit requirements as the business would likely be subject to security and audit review. 

Working with AI is also important as part of the product is a virtual agent tied to the customer and their needs. All of this is laid out in the PRD.

We are a new company with a limited budget so experience working with startups is required. Our goal is to build a working business so you will not be hearing about how we will be the next Uber, Unicorn etc as this is the real world.  Also, this has nothing to do with Crypto or Blockchain and we have no interest in that. 

 If we can find a developer (s) who can work with us the next step would be a mockup to be used in a market validation campaign. Once that is finished and we validate market interest full development would start. 

If the launch is successful and we raise additional capital this can become a long-term engagement.";FinTech
"Have a website with an iframe multistep form. 
No access to iframe source code - cant place GTM container there. 
I'm tracking iframe form submission at this moment - it sends events but nothing beyond that. I would like to enhance it. 

I want to track form steps when people fill them.

Website: mayflowersydney.com";Google Tag Manager
I am looking for someone that can implement a scraping solution on some of our local county websites into a Google Sheet. Pre-Foreclosures, Foreclosures, Probate, Tax Delinquents, Divorce, and Liens;Data Scraping
"We are seeking a full-time E-Commerce Account Manager to assist in Amazon and Walmart data analysis and reporting

The Account Manager will be responsible for daily and weekly reporting along with assisting the team in product management and analysis.  

Amazon Seller, Walmart Seller

Willing to train for this position.  
Annapolis, MD office

-Develop and manage campaigns to increase digital sales
-Create, maintain, optimize and improve our listings on various marketplaces to increase product rankings and sales
-Manage the products reviews on the marketplaces
-Analyze reports from marketplaces to translate insight and growth tactics
-Monitor KPIs (conversion rates, ROI, costs)
-Monitor and manage inventory levels, to include coordination with our plants
-Manage and optimize SEO and SEM strategies
-Report performance of all aspects of e-commerce initiatives

Preferred Requirements and Qualifications
-Bachelor’s Degree in Finance, Accounting, Marketing (Not Required)
-Advanced Excel and Reporting REQUIRED
-Analytical skills
-Great communication skills

Not all SKILLS are required. We are looking to build a team of diversity in all aspects of E-Commerce.  Willing to train!";Data Analysis
"I need to obtain raw hit - level data from Google Analytics which are something like
user_id, event_type, campaign_id, timestamp,

where event_type could be a click on a picture, page opening and scroll and campaign_id is a marketing source of the visit

Each row of a table is an event.

I suppose I want to obtain this data by API with python as a life feed and/or a history and to save into a database.

I will apply this technique with my client who is an e-commerce website, so API rate is a consideration.

I will use my website as a sandbox.

I expect you would explain to me on how to do this in a series of life video calls and share some of your code, if needed. I am a datascientest, python developer  and machine learning practitioner, so will cope with it.

Thank you!";Google Analytics
"Base of this 1 project which I've already implemented
https://github.com/kudawdev/nifi-monitoring-splunk


I would like to improve my spunk dashboard with new functions like:

1. Platform availability  , monitor in splunk dashboard   availability of the cluster and single instance - which I'm already doing in this moment

(image in attachment section)1. Platform availability.JPG

2. Data completeness - mean to verify the data/traffic which I can see only in Status History of the processor

in the image attached,  scenario ProcessGroupId ,componentIds , that number is  to take in considerations

(image in attachment section)2 Data completeness.jpg


3. Data Latency   (Average Lineage Duration)practically to have statistics which are in Nifi under Status History directly under Splunk dashboard   and view the data.

Example:
Average Lineage Duration  base of the host part of the clusters

In the image  is   marked th enumber I need to take in consideration
(image in attachment section) 3. Data Latency Average Lineage Duration.jpg

All this information can be obtained using interrogation of API

Idea is to use python script which interrogate API (using  nifi certificate)
generate a file /json which will be fetch from the host by splunk agent/forwarder

- python will be on every instance in the cluster.
- if one instance is down , maybe and.



My configuration are:
-  9 nifi instances in the  cluster
- Splunk 8 is enterprise and can't use Add one /due to multiple search head and multiple indexes  duplication data.
- I'm not using splunk HEC 

Please let me know if you need more informations";Splunk
"Hello!
We have a client who has Hubspot and Salesforce set up and synced already. We have a Hubspot dashboard and we want to build the same (or similar) dashboard in Salesforce. 

The information is already passed into Salesforce from Hubspot, but we need a dashboard for easy visualization. 

The dashboard currently includes: 
- A list of Current MQLs
- Number of contacts by lifecycle stage
- Campaigns by contacts created
- Contacts created by source

I've attached a screenshot of the Hubspot dashboard (with some sensitive information removed) so you can see what we are pulling now. 

Please respond with an approximate estimate of hours for this project. If you need more information to provide the estimate, please ask! Submissions without the hours estimate will not be considered for this project. 

Thanks!";Dashboard
"We need a true expert in data scraping.

We would prefer to have the script set up for us, we can get a small server if needed but if it will need a complex structure then we are ready to do a compromise for 1-time data extraction as well.

This is not a job for beginners.

We need this job to be completed in max 24 hrs

The website where the data is located has data protection in steps. the first step is to use the ""active"" filter on top of the list so that it will only give you the list of active people. (The website gives you this option to select the active members only)
The total number of records in the active list will be approx. 12000.


2nd step, click on the record, the record will open in a popup on the same screen, at the bottom of the popup there is going to be a link

3rd step, click the link, and then another popup will open with the details like name, email, phone number, and website. ""THIS RECORD IS IN THE IMAGE FORMAT"" that means it cannot be copied only by simply selecting it.

All the data from the image has to be extracted to excel";Data Scraping
"Ecomm business is looking for Data analysis person to dig into product margins, COGs, retail price testing for maximizing profitability. Pricing philosophy.
Also job entails looking into our raw goods manufacturing yields for our build of materials.
Data must be highly accurate.";Data Analysis
"Job Title: Web Scraper and Database Creator

Job Summary:
The Web Scraper and Database Creator will be responsible for designing and implementing web scraping tools to extract data from various sources, and building databases to organize and store the collected data. The scraper will work closely with cross-functional teams to understand data requirements and develop efficient and accurate web scraping processes. The scraper will also be responsible for maintaining and updating the databases, and ensuring that the data is accurate and up-to-date.

Key Responsibilities:
•	Develop and implement web scraping tools to extract data from various sources
•	Collaborate with cross-functional teams to understand data requirements and develop efficient and accurate web scraping processes
•	Write efficient and clean code to scrape web pages and extract data
•	Use automated tools to process large amounts of data quickly and accurately
•	Build and maintain databases to store the collected data
•	Ensure that the data is accurate, up-to-date, and organized in a user-friendly manner
•	Monitor and troubleshoot any issues with the web scraping tools or databases
•	Stay up-to-date with the latest web scraping and database technologies and best practices
•	Provide guidance and training to other team members on the use of web scraping tools and databases
Qualifications:
•	Bachelor's or Master's degree in computer science or a related field
•	3+ years of experience in web scraping and database creation
•	Proficiency in programming languages such as Python or Ruby
•	Experience with web scraping tools such as Beautiful Soup or Scrapy
•	Experience with database technologies such as MySQL or MongoDB
•	Strong analytical and problem-solving skills
•	Strong attention to detail and ability to work independently
•	Ability to work well under pressure and meet tight deadlines
•	Excellent communication and collaboration skills
•	Knowledge of data cleaning and processing techniques
•	Familiarity with big data and data analysis tools is a plus";Data Analysis
"We are a healthcare market research company in Boston and we often do qualitative and quantitative projects using the Qualtrics platform, and we need help with some of the larger, more complex surveys and projects --  especially with survey design, optimization, debugging, and data analytics.

We are also looking for someone to help integrate our survey data with a data visualization platform like Tableau for client reports.";Data Analysis
"Our team uses Excel for hours reporting and project tracking. The current sheet we use displays a forecast of hours available that our team consumes, and we enter data as we work to use that bucket of hours.

I'd like to significantly enhance the capabilities of this report. I'm looking for expertise on how to do this. I'd like to implement some pivot tables to better organize the data, as well as some charts to visualize.
When the actuals are entered, I'd like reports on overages, and how that impacts the remaining hours.
Some examples of the enhancements:
-Show hours by consultant
-Show hours by project
-Show hours by custom date range

While specialization in this project is preferred, I am looking for a long-term relationship so that I have someone to assist with future Excel projects that our organization requires.";Data Analysis
Research email addresses for healthcare businesses and post on a spreadsheet.;Data Mining
"Hello!

We have some Data in BigQuery table, we need to move them to another BigQuery table.
Also need to write some Queries that purges old Data periodically.

Admin,
Trayi Tech";BigQuery
"Hi talents, 
I am looking for a developer to write a crawler/script (preferably python scrapy) for the website glassdoor. The script should crawl job data from the site. It should work on a scale.
I need fields like full job description(this is mandatory), location, salary, job title, company, and job link/url.

Thanks";Data Scraping
An expert in R language is required who has extensive experience of working with r studio and know regression models. Further details will be provided once you submit a proposal as it's an educational task;Data Analysis
"We conducted a in person learning needs assessment:
That have resulted in 3 separate excel documents containing recorded data from 

Manager 9 tabs 
Supervisors 13 tabs
Front Line Employees 26 tabs 

I need help compiling and organizing the data with the goal of creating reports that can generate visuals of the results that will allow us to make decisions.";Data Analytics
"Hello, I am looking for someone to improve my google business setup. I need to do a bulk upload of business data (~55 business locations nationwide) including images. I need to set hours of operation, contact numbers, etc. I need training on future edits and updates.

Additionally, I need training, understanding, and recommendations for google analytics. I want to understand how to leverage google as a platform to generate sales & more.";Data Analysis
"TSI is a moving and shipping company that has 2 divisions: One provides small move and specialty shipping options to consumers and businesses.  The other provides moving and downsizing services for seniors and senior living communities.  We rely on data to help us make business decisions and are in need of some additional help and upgrades to the analytic platforms we use (or should be using). 

The TSI marketing team is looking for a well-rounded analytics consultant to help execute and educate us in a few areas of business intelligence and data analytics.  One objective will be to help transition and further educate us from Google Universal Analytics to GA4. Also provide recommendations and light training on other analytic platforms that might be helpful (ie: Tableau or Data Studios). We would look for this person to understand our general business model, important goals and KPIs.  Then be able to make recommendations and provide specific instructions on which data analytic platforms would best help us achieve our objectives and how. May require some hands on executing of said data analytics.   Some deliverables include:

1) Helping us with transition to GA4. 
*Currently using Universal Analytics
*GA4 is set up and tracking, but mostly just doing the basics. We need to expand and define it better and be ready when Unv GA shuts down.
*Specific deliverables for GA4
	- Setting up and tracking events and conversions
	- Pathing and funnel capabilities and reporting
	- Deeper dive into Exploration and how to create custom reports.  
	- Creating audiences and retargeting
	- Possible ecommerce exploration

2) Additional analytic platforms for combining and analyzing data
*We have multiple digital platforms running different programs and campaigns - paid search, email/automation campaigns, phone tracking, CRM data, etc.  
*Interested in bringing on additional platforms for analyzing data such as Tableau or Google Data Studio. Looking for input on which one is better and why. Or, is there another one out there that is better for us.

3) Knowledge of integrating with CRMs such as Salesforce or Netsuite desired.";Tableau
"We need help setting up Kobold AI with Pygmalion 6B as a base model , and using Kobold as an API into our application. We would prefer someone who can help deploy this on GCP / AWS or Vast.ai but its not a requirement.

Thanks!";Artificial Intelligence
Small matlab project with imaging processing with CNN;MATLAB
"I am interested in training a chatbot to offer suggestions on mushroom identification. I already have a database with species and characteristics. I am considering both text-based guided questions to help filter from a list of 1000 mushrooms, to a few options the user could consider, or possibly something more visual user photos and ""more like A or B"".

I don't know anything about creating these models, or what control I have in maintaining control over the improved models we create. I would like to hire someone to talk with me and possibly work up a very simple proof of concept.

I am open to candidates anywhere in the world but prefer you have availability to be online a few hours between 7am and 6pm US PST time.

You should have earned at least $1000 in previous Upwork projects";ChatGPT
"Looking for someone to pull a list of all companies from few Chamber of Commerce websites and then note their website address and email address

https://business.bethelmaine.com/list
http://business.oxfordhillsmaine.com/list/
https://www.visitmwv.com/service-directory";Data Scraping
"I am looking for an AI consultant.
I need to talk with an AI expert to discuss Deep Learning, Training for our project. 

What skill requires? 
- Fluent in English, 
- Deep knowledge about AI, deep learning, computer vision, tracking, training, 
- TrackNet, Detectron, Yolo frameworks.";Natural Language Processing
We are looking a data analyst to analyze HubSpot data currently saved to AWS Redshift.;Dashboard
"We are looking for an experienced data scientist who's super familiar chatgpt especially its open source alternatives such as GPT-J and GPT-Neo. Also, be familiar with preparing the clear structured training input data thru prompt engineering or other technologies. 

The ideal candidate should be able to present a demo of chatbot that he created before during the interview along with a total cost/timeline range.

Once hired, the idea is to train a simple compiled financial chatbot including creating APIs for a trading app to go thru the entire work flow. Then keep adding more training inputs to enhance the capability of the bot";Chatbot
Looking for an experienced GIS analyst to assist in renewable energy development exercises. You will be working with a small internal team to develop landowner identification maps, setback maps, and environmental constraints maps and other for our internal development pipeline and existing clients pipeline work. We develop both wind farms and solar farms. We are looking for a reliable contractor who can deliver maps quickly. If it is a good fit there is an opportunity to join the company for a full time position and the ability to grow with the company.;Data Science
"Hi all,
    We need to create an AWS EC2 instance which allows a remote user to upload a dataset (2-10 Mb), allows for  another user with access to the AWS server to interact with a GUI, and a then processed data to be downloadable by the external user while the instance is running. We have fully developed the internal data processing application which includes a python and matlab program which interact with each other. General tasks will be

- Creating a method/ sub program for a remote ""user"" to upload and download data that interacts or is generated by the program

- Create an AWS instance that efficiently uses GPUs for running the programs we've developed and allows us to internally interact with a pyqt GUI that the python program contains.

We're in a bit of a rush so the initial goals need to be met within a month but we're happy to continue work beyond the ask if the project is going well. I would be working directly with you for the majority of the time. Per ususal, the job requires the contractor enter into a non-disclosure agreement and sharing of the code outside of our organization will result in legal consequences.

 Many thanks";Amazon Web Services
"Hi there, 

We're working on automating mortgage underwriting. We have already pre-existing algorithms for rules from 52+ Banks. We'd like to combine conversational AI to bridge the gap between rigid rules and complex client cases.

If you have experience in this area - let's connect!";Data Science
"Looking for a Data Scientist who can work around Mexico's energy data, to help build a new dataset and data visualization tools for a new startup. The right candidate will be familiarized with Mexico's official statistics databases, and also will be able to extract business insights by creating a forecasting tool in Excel. Preference to use Tableau for this project, but open to other analytics tools, if necessary.  

This is a short-term contract, but there is potential for more work as we continue to grow as a company. 

Some of the tasks:

* Build data dashboards.
* Build data visualization for an audience of executives working in Mexico's energy sector.
* Organize large datasets. 
* Build an API. 

For those who are interested on this job, you can send your pitch in English or Spanish.";Data Visualization
"Develop and implement web scraping scripts to extract data from target websites.
    Monitor and troubleshoot web scraping scripts to ensure accurate and efficient data extraction.
    Analyze and interpret the collected data to generate insights and reports.
    Work closely with clients to understand their data requirements and deliver high-quality results.
    Stay up-to-date with the latest web scraping technologies and techniques.

Qualifications:

    Strong experience with web scraping tools and technologies, including Python, BeautifulSoup, and Scrapy.
    Proficiency in programming languages like Python, Java, or Ruby.
    Familiarity with data analysis and visualization tools, such as Excel, Tableau, or Power BI.
    Good communication and interpersonal skills to work with clients and team members effectively.
    Bachelor's or master's degree in Computer Science, Data Science, or a related field is preferred.";Data Scraping
"I have a list of 190 web addresses that I need the following information ethically extracted from: 

- All phone numbers (including contact name) 
- Email addresses (up to 4) 
- physical address";Data Scraping
Looking for someone who can help me with data science in finding a job.;Data Science
"We have an existing Abby Flexicapture environment, with roughly 80 different documents being scanned. Our expert resource left the company, and we are looking for a part-time expert to help us implement  changes to our Abby Flexicapture project. We have changes to existing forms that need to be programmed, and we would like to better leverage Flexicapture AI to train the software to better handle slight variations to forms. 

This is an exciting project, and may involve help re-architecting the entire Flexicapture project to migrate it from a Virtual Server to Abby Flexicapture Cloud. We look forward to meeting experts who can demonstrate deep knowledge of Flexicapture, and it's AI and Scanning capabilities.

Required Experience:
- Deep experience with Abby Flexicapture - Currently using version 12.0.2.3063
- Experience with Flexicapture APIs
- Troubleshooting experience - reading an existing Flexicapture project and helping identify why certain forms are failing

We are looking for immediate support, but may require someone for long term vision and strategy planning as we consider a move to Abby Flexicapture Cloud.";Data Extraction
"We are looking for someone to help us set up Google Analytics 4 and optimize how we are using this tool to understand our data. 

Success looks like: 
- Events and conversions are tracking our key web events [webinar registration, generating a lead, and purchasing the product]. 
- Dashboards quickly give us the data we are looking for. 

It's a bonus if you can also provide actionable insights via your own analysis of our data. That could also be a future scope of work once the set-up has been completed.";Operations Analytics
"I need a Tensorflow developer to update a small project from version v1.15 to the latest version. 

More information can be provided during the interviewing process. If you have done similar previous work and are able share it, please include it with your application.";Python
"I will provide all the content for page just need someone who is comfortablw with using wordpress to upload the changes

once thats done: need to add this page on:


Update the home page:
Remove fanquen its written 2x remove both i will send you logo instead
&
Social media icons at bottom of home page should lead to @fanqueen.models

make sure all the colour scheme matches, of text etc.


once thats done: need to add this page on:

fanqueen.vip/boost

page content:

Meet Our Marketing Partners (3d smiley face emoji)

Through Our Marketing Partnerships:
We have a worldwide monthly reach of 21Million+ users and growing!
Our models get access to marketing packages worth RRP $6,500 at no extra cost! (JOIN FOR FREE button)
Really!! Check out our partner testimonials:
https://www.lostteam.tv/   

^ use their testimonial video";Data Collection
track the object in the given video and generate the report has the location (x , y) of the object in each frame. Object can be specified by rectangular coordinates.;Machine Learning
"We need to get data from google maps for the UK market:

Name
Address 
Phone 
category
reviews score and nr of reviews 
Opening times 
Payment types accepted 

Could you help us with that?";Data Scraping
"We are seeking a highly skilled Data Science and Machine Learning Contractor to join our team and work on a women's health data tracking mobile application. As a Data Science and Machine Learning Contractor, you will play a key role in developing algorithms for predictions, analyzing user data and generating insights that will drive the success of the application.

Responsibilities:

Develop algorithms for predictions and analyze user data to generate insights that will drive the success of the application
Create models and algorithms that can accurately predict the user's menstrual cycle and symptoms based on their medical conditions
Work with both structured and unstructured data and be familiar with data storage and management technologies such as databases, data warehouses, and big data platforms
Use data visualization tools, such as Tableau or PowerBI, to help communicate the results of their analyses to stakeholders
Collaborate with the front-end and back-end development teams to ensure seamless integration of the application
Ensure the security and privacy of user data through encryption and other data protection measures
Stay current with industry trends and advancements in the field of data science and machine learning
Requirements:

Strong expertise in data processing and analysis, algorithm development, and machine learning
Familiarity with statistics and mathematical modeling
Knowledge of women's health and the specific data requirements of a menstrual cycle tracking application
Experience with data visualization tools, such as Tableau or PowerBI
Strong understanding of data security and privacy measures
Proficiency in JavaScript is a plus
Excellent communication and collaboration skills
Ability to work in a fast-paced, startup environment
If you are an experienced Data Science and Machine Learning Contractor with a passion for using data to drive business success, we would love to hear from you. 

Please apply with your resume and portfolio to be considered for this exciting opportunity.";Data Analysis
"We are looking for a talented and detail-oriented Analytics Specialist to help us migrate our web properties from Universal Analytics to GA4. There are about 15 websites altogether.

You will be responsible for updating our tracking codes, implementing Google Tag Manager, and ensuring that our data and analytics tracking are accurate and up-to-date with best digital marketing practices.

Responsibilities:
- Migrate our web properties from Universal Analytics to GA4
- Update tracking codes and implement Google Tag Manager
- Ensure accurate and up-to-date data and analytics tracking
- Collaborate with our development and marketing teams to ensure proper tracking is in place
- Troubleshoot any issues that arise during the migration process

Requirements:
- Experience with Google Analytics and Google Tag Manager
- Strong attention to detail and ability to troubleshoot issues
- Familiarity with web development and coding
- Excellent communication and collaboration skills
- Ability to work independently and meet deadlines

If you're passionate about analytics and excited to take on a new challenge, we'd love to hear from you! This is a freelance position with the potential for ongoing work.

To apply, please provide a cover letter highlighting your relevant experience and expertise, along with your resume and any relevant samples or work examples. We look forward to hearing from you!";Data Analysis
I have a large amount of data that needs to be scraped from an email archive export, placed into a database and then read from a website with search functionality. MySQL, AWS cloud storage, PHP, linux knowledge needed.;Data Extraction
"We are looking for someone to help us build a google sheet that is constantly scrapping property information from Zillow and in the future MLS in specific zip codes. This bot would crawl Zillow/MLS and other property listing sites to extract the information and input it into a google sheet.

This would include information like: Property address, asking price, square feet, beds, baths, etc

Here is a example google sheet: https://docs.google.com/spreadsheets/d/1n0pei8R8ArahwZkZtLZD6HYOgasj91R_CfsTQqFLDU0/edit?usp=sharing";Data Scraping
"We are looking for a highly skilled software engineer to develop a high-frequency trading bot for our financial services company. The ideal candidate should have experience in developing trading bots and be familiar with high-frequency trading strategies.

Responsibilities:
• Design, develop, and implement a high-frequency trading bot that can operate in real-time and execute trades quickly and accurately.
• Collaborate with our team of traders and analysts to implement and optimize trading strategies.
• Perform testing and debugging of the bot to ensure its stability, reliability, and accuracy.
• Monitor the performance of the bot and provide ongoing support to ensure its continuous operation.

Requirements:
• Bachelor's degree in Computer Science or related field.
• Proven experience in developing trading bots and using API to connect to financial exchanges.
• Strong proficiency in statically typed programming languages such as Rust or C++.
• Knowledge of high-frequency trading strategies and algorithms.
• Experience with data analysis and machine learning techniques is a plus.
• Strong problem-solving skills and attention to detail.
• Ability to work independently and as part of a team.

If you are passionate about high-frequency trading and have the skills and experience we are looking for, please apply for this exciting opportunity.";C++
We are looking for a top notch algorithmic trader who has a proven track record trading strategy for European power and gas futures contracts and/or Brent, WTI, Emissions.;Market Analysis
Looking for experienced data engineer to help with designing datawarehouse schema, ETL & performance tuning using Redshift & AWS Glue;AWS Glue
AWS Data Lake, glue, crawler assistance needed for a new and existing implementations;Data Lake
"We want to build a bot to vote 1 million times for Yiorgos Georgas, Suffern for this link

https://www.lohud.com/story/sports/high-school/lohud-wrestling/2023/02/13/vote-wrestling-lohud-wrestler-week-champions-edition/69897592007/

If you can have it ready immediately (next 30 -45 minutes) I will pay you 2x your rate.  Thank you";Data Scraping
I need a web scraper to gather data off a state ran website of new business formations to capture business name and contact info from individual web pages. Each page has a unique Biz ID code and also a unique URL. The data needs to flow into an excel sheet I can then do a mail merge from for mass email marketing, and phone numbers for follow up calls. In my mind this job is fairly simple but I'd like to talk through the specifics before starting.;Data Scraping
"I need someone help create a dashboard on Google Sheets to display specific data from my 2 sales channels:

- Shopify (data will be taken via API)
- External system (data can be updated via CSV)

Data I would like to see visualied is:

 Daily Sales (broken down by channel), Weekly Sales, Monthly Sales, Annual Sales
 Gross Sales / Net Sales
 Refund Analysis at product level
 Discounts used
 Margin
 Profit / Loss
 Average Order Value
 Best Sellers by time period

You must have experience in this type of work.";API Integration
"Hello,

We are looking professional Lead Generation and Data Collection expert for our project gyms fitness clubs of United State. 
Our Targets 1200 fitness club of United State. We need these club data from Yelp.com or other tool So, need all data find from using yelp, and any other paid or professional tools.

Require Data Of Fitness Clubs:
-Club Name
-Phone
-Website
-Address
-Founded
-Full Name
-Title Owner
-LinkedIn URL

Important Note:
We need 100% real data not fake and 90% data. If you not collect real data of targets site So, not apply on this job If you collect real data so, feel free for apply on this job.

Thanks,,
Laura";Data Entry
"Looking for an experienced and talented person to help our team on research projects using generative AI. The focus will be on using the Open AI stack to create models and programs to for specific tasks that aid end users. Candidates must have experience:

-With OpenAI API and methodologies 
-Training, fine-tuning, and improving open AI models for specific tasks
-Segmenting and normalizing textual data and code for use in tuning open AI
-Evaluating the quality of AI responses and advising on a strategy to improve them
-Advising and implementing supervised learning to improve AI models.

Experience with Weights and Biases a plus.";Data Science
"Looking for expert writers that are educated with their degree in Nutrition, Dietetics, Exercise Science, or a related area. We do prefer a Masters degree or above. Those with a Bachelors will be considered if the candidate can show demonstrated knowledge and experience in nutrition and dietetics.

You will write on an ongoing basis about Nutrition education.

This is an ongoing contract and we are looking for writers that can:
1.  Write a minimum of 3-5,000 word articles/pieces of content (long form, in depth)
2.  Write in Notepad or Notepad++ or a similar text editor (not Word)
3.  Be trained on SIMPLE HTML (we can advise and work with you on this!)
4.  Be timely, consistent
5.  Research appropriate sources (we will give direction) and colleges/programs that are within Nutrition, reviewing and writing in your own words, succinctly.
6.  Opportunity to be posted as a contributor on our website along with a headshot and writeup (you must first pass our editorial review and post articles to be considered as a contributor to our website)

How we see this working:
1. We will assign a specific article to you as we see fit, which will include the title, word count you should achieve, and outline to follow.  
2. You research and write the article in HTML, using our outline structure and we do allow you to add other heading tags or lists as you see fit to well-organize the document
3. You submit the article via Upwork messages";Data Analysis
"Job Title: Natural Language Processing Coach

Company Name: Colorado Mental Health Solutions

Location: Remote

Type: Contract

Pay: $100/wk (One 30min weekly zoom call Sunday afternoons)

About our company:

This is a healthcare initiative that strives to transform the industry by utilizing cutting-edge technology to detect symptoms of burnout among healthcare staff. Our team is committed to making a significant impact on employee well-being, retention, and healthcare costs. We're currently seeking top-tier individuals to join our remote team in Colorado and lead the charge towards our national expansion. 
The job is expected to last 7-15 weeks and will require you to provide high-quality, one-on-one training via zoom to our Colorado Advocacy Coordinator. You will be tasked with assisting in their professional development and will be expected to have weekly 30-minute phone calls to review progress and provide input based on strategic organizational goals. In addition, you will be expected to participate in high-priority calls with the coordinator during client communication to offer your expertise.

The jobs requires you to be available for 30 minutes for a zoom call every Sunday to give your input during the weekly sprint review & planning brief for 7-15 weeks.

About the role:
As an NLP Engineering Coach, you will play a crucial role in helping us become the leading provider of sentiment analysis technology for nonprofit hospitals in Colorado. The campaign will assist healthcare organizations struggling with employee burnout by developing and donating a state-of-the-art stress monitoring system. We are committed to making a difference and are offering a lifetime license with software updates to one nonprofit.

Our team of high-performing and dedicated individuals share a passion for combating mental health conditions such as MDD

Nice to have:
• Bachelor's or Master's degree in Computer Science, NLP or a related field
• 5+ years of experience in NLP engineering and software development 
• Strong understanding of NLP algorithms and techniques 
• Experience in data science and sentiment analysis 
• Excellent communication and interpersonal skills 
• Strong problem-solving skills and attention to detail 
• Ability to advise executives

As the NLP Engineering Coach, you will be accountable for providing the best, live, case-based advice to the Colorado Advocacy Coordinator and ensuring a smooth delivery. If the donation is successful, there is potential for future contracts and opportunities for growth as our team improves coordination and experience.

We are seeking individuals who are passionate about healthcare technology and dedicated to making a positive impact on well-being. If you are up for a challenging and rewarding role where you can work hard, compete and make a difference, we encourage you to apply.";Data Science
Looking for someone to help audit our marketing material to make sure everything complies with IIROC and Canadian securities commisions;Neural Network
"We are seeking a highly skilled Data Expert with experience in Google Analytics, Power BI, and Tableau to join our team. In this role, you will be responsible for analyzing and interpreting large amounts of data from various sources to provide insights and recommendations to our clients. You will be responsible for creating reports, dashboards, and visualizations that effectively communicate complex data to both technical and non-technical audiences.

Responsibilities:

Analyze large data sets from various sources, including Google Analytics, to identify trends, patterns, and insights.
Create reports and dashboards in Power BI and Tableau that effectively communicate complex data to technical and non-technical audiences.
Develop and implement data analysis strategies to identify areas for improvement and growth.
Collaborate with clients to define and refine business requirements for data analysis and visualization.
Manage data quality and integrity to ensure data accuracy and consistency.
Train and mentor junior team members on data analysis and visualization techniques.
Requirements:

Bachelor's degree in Data Analytics, Computer Science, or a related field.
At least 3 years of experience in data analysis, with a focus on Google Analytics, Power BI, and Tableau.
Proven ability to analyze and interpret large amounts of data and communicate findings effectively.
Strong skills in creating reports, dashboards, and visualizations in Power BI and Tableau.
Proficiency in SQL and data visualization tools.
Excellent problem-solving skills and attention to detail.
Strong communication and collaboration skills.
If you have a passion for data analysis and visualization, and experience in Google Analytics, Power BI, and Tableau, we encourage you to apply for this exciting opportunity. We offer a competitive salary, benefits package, and a supportive work environment that values creativity and innovation.";Data Analysis
"Hi there!

I need the data of a webshop that contains required books for certain studies.

A lists contains:
1. Book title
2. Author name
3. Title
4. ISBN

Here is an example:
https://www.studystore.nl/boekenlijst/Aeres-Hogeschool/2022/BL119148/Duurzame-Bedrijfskunde-Associate-Degree-Jaar-1

To learn how to get to the list I made a short video instruction.

A lists belongs to:
1. Hogeschool, universiteit, Studievereniging, overige
2. Name of education
3. Year
4. Sub title
5. sometimes other fields

I would be best to kick-off the project with a short Zoom call to give you further explanantion. Please, also see example Excel sheet, containing data from a similar webshop, to give you an idea of what the expected end result would look like.

Hoping to hear from you!

Mark";Data Scraping
"Hi there! Wir sind ein Mental Health Startup aus der Schweiz und suchen eine Person, die mittels Internet Scraping Kontaktdaten für uns zusammenträgt.

Ziel: Bestehende Kontaktliste mit Daten aus dem Internet ergänzen.

Ausgangslage: Wir haben bereits eine Kontaktdatenliste mit 3572 Leads, welche bei 1688 Firmen angstellt sind. Pro Firma sind jedoch nicht alle Mitarbeitende erfasst, sondern meistens nur die Entscheidungsträger.

Aufgabe: Du wirst die Firmen unserer Liste durchgehen (URL ist meistens vorhanden) und die fehlenden Mitarbeitenden nachtragen (sind meistens bei der ""Team"" Sektion auf der Webseite aufgeführt). Falls die E-Mail Adresse nicht auf der Website ersichtlich ist, muss diese im Internet gesucht werden (hohe Erfolgschance, weil Therapeuten ihre E-Mail Adresse oftmals öffentlich angeben). Wir rechnen damit, dass noch ca. 1800 Leads hinzugefügt werden müssen.

Falls Du Dich in der Aufgabe siehst und Du etwas im Mental Health Bereich bewirken willst, bist Du hier goldrichtig.

Gutes Deutsch wird vorausgesetzt.";Data Scraping
"We have analysed the 16S rRNA sequenced data (tables are available), and we need to plot the graphs of this data.
The project is about comparing the nasal microbiome composition between two types of nasal collections. 

If you are interested, please let me know to I can discuss this study in detail.

A million thanks.";Data Analysis
"Location: Remote

We are seeking a highly skilled web scraping expert to collect real-time data from the news website, CoinDesk. 

Once a news article is posted on this site, we should be able to have the headline and raw text of the article within seconds.

We need to make sure we do not get our IP blocked as well. This should be running 24/7";Data Scraping
"Need a program to do the following on TOR sites:
1. Given a list of sites:
 - Identify if a site is active (daily)
     o Display (red/green) if it is active or down
 - Identify any changes on site (daily)
      o Scrape new information
      o Use a mail icon next to the site name to indicate there is a change and the site has been scraped
  - Rotate ip addresses to prevent getting blocked
 - With a list of keywords, search scraped data for those keywords; display associated information (website, time scraped, all data)

2. Use bots to search for other active sites on TOR
     - Once an active site is found
          o log site address in a list
          o identify things such as name, addresses, identity numbers; if it exists, scrape data and indicate with mail icon

3. Display above on a monitoring server (located on AWS).  Be able to output data to html, pdf, or email format.

4. Open to additional ideas. End state is a TOR web scraper looking for companies attacked by ransomware actors, then display information on a monitor.";Data Scraping
"The most time-consuming thing at the university is writing summaries.

So I had the idea of creating a platform where you can upload your lecture slides (mostly Powerpoint slides as a pdf) and it returns to you a useful summary that you can use for your exam.

Who's joining me?";Artificial Intelligence
"Job Description:

We are looking for an experienced Instagram Scraper to help us gather data on Instagram profiles that are using a specific hashtag. The ideal candidate will have extensive knowledge and experience in data scraping from Instagram and will be able to provide us with accurate and detailed information on each profile.

Responsibilities:

Develop and implement a scraper to extract data from Instagram profiles that have used a specific hashtag. (even better if you already have one)
Collect and organize data on Instagram profiles, including the number of followers and engagement metrics.
Ensure that all data collected is accurate, complete, and delivered in a timely manner.
Requirements:

Demonstrated experience in web scraping and data mining from Instagram.
Proficiency in programming languages such as Python or JavaScript.
Strong attention to detail and ability to deliver accurate results.
Familiarity with Instagram's terms of service and guidelines regarding data scraping.";Data Scraping
"Need to crawl and scrape a website for one time. 
I need someone with experience and that can create the code in Python. 

Part of the delivery will be the data + the code so we can utilize it.

We need only an expert for this job with more than 1000 hours on Upwork Thank you";Data Scraping
"I am launching a new SaaS offering on Feb 28 (it might be slightly delayed). I have a new site for it with CTA's to sign up for the service. Currently, I am only accepting emails for people to get on a waiting list. 
My WordPress developer has set up UA, GA4 with GTM, but he is not an expert and changes are too difficult. I need to find a better person. 
Their are several places on the site where a visitor can click on sign-up buttons that all take the user to the same page. If they then sign up, they get a thank-you page which is being tracked. 
I need to know what sources users used to find the site, and if the traffic converted so I know what works best. Google Ads tracking has been set up although I have not started to drive users using it just yet. 
I have included UA as part of the ask, but know it's going away in July, so not critical. I am hoping that someone can create GA4 reports that are more similar so I am more comfortable using it that I am now. Currently, I still prefer UA.  
I need someone to audit the current set up; remove my IP address so I only see external traffic; make sure Bounce rates are being recorded correctly, which I am sure they are not and clean up the reporting so I can better analyze traffic and conversion rates. 
When we launch the SaaS service, I will want the person to track the usage of the service.  
Please let me know what relevant skills you have to help with the above.";Google Analytics
"Marketing agency looking for a consult on building Google Looker reports for multi-unit franchise clients. 

We currently have a junior marketing associate tasked with the generation of these reports and are seeking a consultant to aid them in ""how to"" build the reports out.

Need 1-3 hours of consultation that would be done via a screen share to basically hand-hold our marketing associate through making one report that would be used as a template.";Google Data Studio
"MAIN PURPOSE OF THE ROLE

Are you a search engine guru? Can you find what you're looking for with just a few keywords? We have a unique opportunity for you to put your skills to the test!

Welocalize is looking for an Estonian speaker in Estonia to help support our client's project as an Ads Quality Rater. 

You will use a unique, web-based tool to evaluate search engine advertisements based on project guidelines. 

Project Details

Job Title: Ads Quality Rater
Location: Remote (Must be based in Estonia)
Hours: Minimum 5 hours per week, up to 20 hours per week; set your own schedule (Expect occasional peaks and dips in work)

Fluency in Estonian
Fluency in English
Strong understanding of popular culture in Estonia
Web-savvy and able to work in a fast-paced environment
Excellent online research skills
Reliable computer system and internet connection 
Reliable anti-virus software (as you will be surfing the web as part of the work)
Ability to follow instructions in English and comply with the project conventions and rules expected by the client
Must sign a Non-Disclosure Agreement to protect client confidentiality
Must pass a learning program and a rigorous quality test designed by our client before starting work

Apply here: https://jobs.lever.co/welocalize/133002e7-e660-48de-b538-858c9cfb64cf?lever-origin=applied&lever-source%5B%5D=UpworkMP";Estonian
I need to create a master inventory list built off of several diffrerent data sources. We have an estimate of 20-30k products with 30-40 different attributes that need to be merged using specifc file requirements for a marketing platform.;Microsoft Excel
"I am looking for someone to collect contact information in the following way:

Collect the information on worksheet provided by us. Including company name, address, phone numbers, etc.";Data Entry
Create a machine learning model and integrate with a working code/;PyTorch
To extract data related to product listing such as product name, image, price, etc. And add it to a google sheet.;Data Entry
"Hi Nermin, 

im working on a project of building few telegram channels and exporting db from linkedin towards marketing use. 
can you do such a thing? 

thanks,";Data Scraping
Now Google is enforcing the upgrade from Google analytics to Google analytics 4, we would like to upgrade that for all our clients - We are a London-based marketing agency with 9 active accounts.;Google Analytics
"I want to create an AI jersey swap tool. In essence you would drag multiple photos of a player in their current jersey and then multiple photos of players in another teams jersey. 

You would enter the number and potentially name on the back of the jersey to generate the image of the player in the new teams jersey. 

This will give you a good example of what im looking the tool to do automatically: https://www.youtube.com/watch?v=f5ocn9JGRqQ";Model Optimization
"I am looking for some advise on how to configure BO 6.5 across multiple servers.

We are a PeopleSoft Shop with their EPM layer that includes BO 6.5.  The consultants and developers that were part of that initial project have been gone for many years.  We provide WEBI for many of our users and produce a great deal of reports via a VB program that calls the BO layer for a user/report that is then emailed.  Today all that runs on the same machine.  We want to move the VB distribution process to a new machine.  We want the BO databases and documents to be shared.";Google Data Studio
Looking to produce some reports on Zendesk that will tell me total inbound calls, time spent on calls, total calls taken and total outbound calls in total and at a per agent level.;Data Analysis
"System conversion in July, looking for someone to build new SQL reports to mirror our old reports. Old system is Hyphen Solutions/BRIX, new system is ECI/Marksystems. 
Looking for experienced report writer with experience in our industry, if possible. Consultant position only.";Data Entry
"ONLY FR SPEAKERS : Urgent : For at least 12 months team reinforcement, we need SENIOR datas engineers

IF YOU ARE NOT SENIOR WITH MINIMUM 5 YEARS OF EXPERIENCE IN DATA ENGINEERING / SCIENTIST DON'T APPLY.

Technical stack : to define

--FR TRANSLATION--

Nous recherchons urgemment des data engineers / data scientist senior avec au minium 5 ans d'experience pour une mission longue.

Si vous êtes intéressé merci de candidater";Data Engineering
"Startup trying to better understand frequency of app usage broken down by feature and by user

1. Need to first assess if all the required data is actually linked
2. Breakdown app visit frequency by user 
3. Breakdown feature usage by user";Data Analysis
Need Land Surveyor to evaluate survey and photos and then testify about conclusions regarding whether tree trunks cross property line.;English
"Looking for someone who can solve problems and use AI, namely OpenAI's ChatGPT and Playground in various areas of the organisation to become more efficient at generating written content.

You don't need to have much experience building AI tools, but if you've used OpenAI's ChatGPT or Playground, and are interested in helping us use this tool more effectively, this could be for you!";ChatGPT
"Good Morning!

Our company, ADS Data Direct, is looking for a Data Scientist! 

This is will be a test opportunity that will turn into a long term opportunities. Benefits, hourly salary, and bonuses will be discussed during the interview process!

A couple things to expect include:

Stardardize large files
Merge the files together.  
Provide data from those files based on the fields we give them and send us the data sets.  
Be able to upload it to our FTP and help us deliver data regularly.  
The biggest challenge is working with a terabyte of data. 

Let us know your background, resume, and looking forward to hearing from you! :)

Best,

Andy S.";Data Science
"For our newsletters and flyers that we send by mail, we need email and postal addresses.

Task: 
1. We give you the institutions to look for. 
2. you filter the addresses and create an Excel sheet.

We are talking about regional addresses.";Data Scraping
"Deadline: March 6th, 2023

Go through an online learning experience to review and provide feedback on Classify Data and Make Predictions With KNN and SVMs Learning content based in Python and ensure the accuracy of coding exercises and provide feedback on the instructions. For this job you will be asked to:
- Go through an online learning experience and complete the practice coding activities using Python and pandas in Jupyter Notebooks to provide feedback on learning content.
- Provide feedback on the activity instructions and accuracy by filling out a provided QA template and writing in-line comments in a Jupyter Notebook.
- Submit coded solutions in the Jupyter Notebooks with feedback on the coding prompts and code required to solve them.

We are looking for candidates that have experience in:
- Python and pandas
- Supervised Machine learning
- Classification
- Data cleaning
- Train/Test split
- Model creation and training
- Model evaluation

Please confirm you can meet the March 6th, 2023 due date.";Data Science
"We have initial NN structure and data-set, we are looking for someone to finish the project:

- Analyse training / prediction performance, fix bugs
- Perform optimization of NN 
- Train the model & help with integration

Preferred someone with experience in NN and tensorflow who could work full time for 2-3 weeks.";Machine Learning
"URL WITH SAMPLE CODE: https://github.com/amiradridi/Job-Resume-Matching

Requirements: - 
1. Enhance the existing app to use https://api.lightcast.io/apis/skills - this can be invoked periodically to get skills. Caching to be implemented and resultant json file saved on DB.The skills.json file which is used in conjunction with labels.json should instead use the lightcast API.
2.Enhance the matching rules (Rules.py) to also accept matching by different criteria or weight matching by different parameters( University Name, Gender, Race (??) etc)
3. Currently the data used (job_description.csv, resumes_by_spacy.csv) are pre-generated and used. This should be driven from passing in resumes and job specification.
4. The degrees.json and majors.json should be enhanced to cater for all degrees and majors in the world (include UK degrees naming and awards)
5. The resume ranking should show attributes used to rank (each attribute score shown) with overall rank showing the job it ranked and the resumes in order of priority. (Top 10 )
6.Ranked scores should be persisted to the database and if nothing has changed the app should return the persisted scores.
7. Currently the app parses all resumes and all job postings. We need the segmentation of skills to be done from the skills.jso and labels.json so that professional skills of a given profession are demarcated and grouped together. i.e if we have say for example skills for a data scientist, pharmacist, Physicist, BioInformatician, Psychologist etc etc  demarcated and we get resumes of a Pharmacist to parse against a Pharmacist role, we would only consider the skills and taxonomy that pertains that profession and not waste compute resources trying to match skills for other professions not related to say Pharmacist.";Data Scraping
"I have had an engineer who has taken a leave from our company for an undetermined amount of time.  I am looking for someone who I can contract out work to if we need adjustments/improvements made to the spreadsheet going forward.  Thus there is not any particular project or job, but just an on-going support (analogous to IT support I suppose).

Is this something you would be interested in doing?

Sincerely,
Gordon Leaf
President
Sunset Memorial & Stone Ltd";Data Extraction
"Hello Martin.  This one seems fairly simple even though its very frustrating for me.  I have to enter dates into a platform.  The dates i have are in 3 columns but I need them to read ' 12/07/22"" for example.  I've been painfully entering them one by one.  I've already spent too much time on this.  I have several more reports to work on (each with a few hundred lines)";Data Analysis
Option strategy developer through algorithm in Derivatives;Python
"We have on our website a coverage per product visualisation: https://level421.com/coverage/

Each of our products does offer a different coverage. Coverages does change over time.

Starlink for example does visualise their coverage with the following map: https://www.starlink.com/map

We are seeking for a convenient tool we can dynamically edit coverages on a per country base via a backend. This shall automatically visualise on the website.

Informative to the end user, we do provide coverage either by SATELLITE or by 4G/5G GSM. Within a legend, we want to provide as additional information to the end user, which countries are covered with which kind of technology.

As some countries are really small and might not get proper shown on the map, we want also a verbal list of countries to be provided in the visualisation. Just for the end user to be sure that service also can be provided in small areas such as Andorra, Monaco, San Marino or other places.

Optional to the contract, coverages on waters can be included, such for example East Sea, Black Sea, North Sea, Baltic Sea ect...

For Maritime coverage visualisation, an additional milestone will be provided.";HTML
"create a forecast map with temperatures updated.

grab datas from api open weather, create a list of countrys from all continents and match the temperatures .

celcius fareneith and kelvin needed.

place those datas in a db and display the temperatues on a high resolution world map.
https://en.wikipedia.org/wiki/Wikipedia:Blank_maps#/media/File:BlankMap_World_simple.svg

this world map, must have an automatic update of the countrys temperatures in real time with the datas collected";Python
Looking for Medicare star ratings and area populations (5, 10, 25 mile radius) for 4 NH properties in FL, USA.;Researcher
I do have child atlas wants to apply on surface level and refine some images;Data Science
"From the perspective of actuarial pricing model and insurance product design (property insurance, or non-life insurance), suggestions and guidance on the sales side; Please give examples of the customer analysis, product positioning, or the data and direction of the project that the salesperson should focus on.

Please search and organize a 30-mins speech draft as well as a PowerPoint.";Data Science
"With an iOS or Android phone, record video of a ball bouncing against a wall back and forth (see examples) - variation is desired.

Produce lots of video clips
- 5-30 seconds each
- so 3-20 bounces agains the same wall: throw/roll - bounce - catch - repeat
- perhaps 5-20 video clips of each situation with slight variations. below are some ideas
- record in portrait mode

Ideas:
- If you have more than one ball at hand, use different ones. ideally 5-10 cm in diameter. Could possibly work with larger ones too but the ideal ball is smaller than a football and larger than a golf ball, closer to a tennis ball...
- use different rooms and different walls with varying textures on the floor and wall, with carpet, without carpet etc
- do it from different angles
- Potentially you could handhold the camera in 10-30% of them so that there is some movement, nothing och erratic though. For at least half of them: put the phone camera on a stand or prop it up against something to get a completely static image without any camera movement
- Use a smartphone camera, but if you can, use more than one phone so that the variation in optics etc are represented
- a varying amount of random background noise would be good too. Sometimes complete silence, sometimes a tv on, someone doing the dishes, whatever you can come up with that might happen in a household
- hands in the shot, no hands, feet, ...: all ok, again, variation is good
- the start and end does not have to be perfectly timed, it is a good thing if a minority of the clips include picking up the phone, laying down the phone or framing incorrectly at the start/end, like a normal user would if this was part of a mobile ar game

For each video file, count the number of bounces against the wall. then create a text file next to the video file with the same name but a different extension. Example:

IMG_3221.mov
IMG_3221.txt

Keep the video filename as it comes out of the phone, that’s fine, doesn’t have to be exactly IMG_…

In the text file, add your observations, using the structure below. After each colon, specify bounce count and ball color. And for type specify either steady or handheld.

bounces:
color:
type:

Or if you prefer, you can use a Google sheet or excel and use the corresponding columns i.e filename, bounces, color, type, with each video clip on its own row.

Perhaps this is a quicker workflow than the text files? The data is easy to consume either way

Why do all of this? We are training a machine learning model that once trained on a sufficient amount of data, is supposed to be able to watch other videos and make good predictions about ball color and no of bounces. We intend to do this visually but might also attempt to do it by audio analysis, so variation in the audio situation is good too - including making noises a naive mode might interpret as a ball bounce

If the AI model eventually gets good enough it might be used in a mobile game where the user is supposed to bounce a ball and the app keeps track of the count automatically.";Data Collection
"Looking for data engineer, with ETL, SQL Server, Oracle, R, Python, Azure. 

if you know some statistical analysis will be great.
Only freelancers and must work in USA hours.

Posted my budget in job so anything above will be rejected.";Data Analysis
I have raw data of 50k rows. The spreadsheet is very poorly formatted need to uniform the formatting and  information. Also Need to remove out duplicates and bad data.;Data Segmentation
I'm looking for an expert in Alteryx who given sample subset of anonymized data can create small apps for data treatment;Alteryx, Inc.
"Porifera is a startup company building a data collection and integration platform for Cyber Security Industry. The developer will be working with the head of development and other developers to develop pre-defined detailed architecture and design.

Requirements:

1. BSc. of Computer Science or equivalent experience.
2. 5 years of experience in software development.
3. Hands-on experience in systems programming using Golang.
4. Familiar with SCM Software (e.g., git), CI/CD, testing frameworks
5. Able to write scalable, efficient, clean and testable code.
6. Knowledge of software design principles, different programming paradigms (for example OOP vs Functional and the trade-offs between them), design patterns, etc.

Pluses:

- Experience with Java, MongoDB, SPA Frameworks (especially Angular), JavaScript, TypeScript and frontend web development (HTML, CSS).
- Experience with Apache Kafka
- Experience with containerization systems such as docker and Kubernetes.
- Experience working in the field of Cyber-Security";Golang
Need a data analyst who is proficient in working with Excel that can help to analyse our data and also create a dashboard;Data Visualization
I'm trying to connect an API (https://api.storedgefms.com/docs/v1.html) to PowerBI;Microsoft Power BI
"This job will only commence on the 27th Of Feb 2022, 

I will share a video of a meeting I have with team members regarding what issues they have on their excel, whereby it freezes and locks up, 

Its a very very complex excel, but I think most of it works already, 

Due to it needing credentials to log into the work domain I cannot share these details with you, However We can arrange certain work hours whereby you can remotely use my PC whereby I will log in when ever needed and you can fix the issues, 

I will monitor what you do not for time recording purposes but just for security purposes, so if we discuss and its 100 $ and you take 2 hours to fix everything than great for you and me we can both move on happily. 

I will be sure to synch up a time slot whereby both parties are available for collaboration, 

My typical hours of availability are as follows: 

in GMT +2 time zone  (12h30 to 16h00 )  ( 19h30 to 23h00 ) 
Alternative times can be made if required. 

Time to complete it about a week should suffice so around first week march";Data Analysis
"bioinformatics admin support.  We create online platform and need supper with operational tasks. 
emails, verification, platform testing etc";JavaScript
Using data downloaded from leasing software create an excel workbook that provides an analysis of data provided to show monthly performance and charts KPI's and results.;Data Visualization
I need to do analysis for my master thesis and I really need your help. I have panel data and I need to do descriptive statistics, Fixed Effects and Random Effects models and GMM for robustness check in Stata plus graphs. I am in a little bit of a time crunch and need the results within a week and I don’t know if it’s possible or not. I have the data and it is ready for analysis.;Data Analysis
"Given the following data:


1. List of prices - 8-10 different possible prices to be assigned
2. Product ids and revenue per product id


Write a python function that assigns prices from the price list to every course id, so that the total Price Weighted Average (weighted by revenue) approximates a given Target Price Weighted Average

The function should work with different combinations of possible prices to be assigned and revenues per product id

In other words, what price should I assign to each product to obtain a specific overall target weighted average price";Data Science
"AWS Athena / Glue ETL / Data Schemas / Postgres Ingestion / ETL Jobs

- Ingest Athena data to Postgres
- Fix Athena schema issues
- Design ETL jobs in Glue Data Brew
- Implement Glue ETL jobs in Python a Shell

- AWS QuickSight Experience (IF POSSIBLE - BUT NOT REQUIRED)";Data Engineering
"To generate a 3D point cloud using photogrammetry, we need a suitable algorithm for our iOS iPAD application.

The 3D points are based on the robust recognition of distinctive real corner and crossing points (2D pattern recognition).
The starting point of the pipeline is the SDK function of ARKit (iOS/apple). Here, individual frames with intrinsic and extrinsic camera parameters are made available from the video stream.

The necessary pipeline consists of the following components:

1. ARKit

2. frame

3. Pattern recognition/ 2D feature for prominent corner points

4. Matching of the 2D feature between the individual frame sequences

5. Triangulation and reconstruction of the 3D points between the keyframes

6. local bundle adjustment (Ceres solver) for each individual measurement 

7. Storage of the 3D points of each local single measurement in a common global reference system (octree).

The 3D point cloud is used to overlay or register CAD models with reality (augmented reality). (Not part of the task)

The following skills and experience are beneficial for the project:

- Image Processing ( 2D feature / Descriptor / Matching)
- openCV
-Photogrammetry (Camera model)
- GPU (OpenCL /Metal)
- 3D reconstruction
- Ceres solver BA

A prototype for the pipeline already exists.
The task is to extend and optimize the algorithm.";Computer Vision
"- We are looking for a person who can provide us with 2 articles per week.
- We are keen on knowledge regarding the business side of ML, AI and other Data Science solutions. 
- Our blog is aimed at business people, not technical people. 
- The goal is to educate regarding the possibilities behind Data Science solutions.";Data Science
"We are looking for a hotel and it's property for sale. We'd like to go to the bank for a leverage buyout so then we'd need to see their financial statement (preferably audited version ones).

I need you to conduct a research, possibly reach out to their PIC to fill in their property's & financial detail.

Please check here :
https://docs.google.com/spreadsheets/d/1a3-46emNsQE5sa2MW6dUCUexOV1Xc75m9eECTa4WIpc/edit#gid=0

Criteria : 
- We're looking for the ones that are located in south east asia, located in high tourist traffic locations such as Phuket & Bali, as well as generating at least 28% net income/revenue ratio since the past 5 years.
- Hotel for sale, which generates net income since the past 5 years and the net income continuously exponentially growing
- The net income should be at least 28% of the revenue since the past 5 years continuously hence never drops through out the 5 year period
- If we buy it through a leverage buy out, hence it means; the forecasted monthly net income should be able to cover the monthly installment payment. We can check this by analyzing the past 5 years net incomes.
- The Financial Statement has to be audited by a well known financial public accounting firm

----------

You can find your own way in how to retrieve the data, but here's my method that you'd want to know : 
Just go to google, ex : 'find a hotel for sale in Bali'. Then reach out to the property seller's Person In Charge, prnt.sc/w3QRlxZqTFFb. Then you can ask them all of the details I've specified in the Gsheet hence fill in the Gsheet accordingly.

Let me knows if you are confident to succeed on this.

--------

Which Payment Scheme would you like to go with ?
 
A. Paid $50 per 10 audited financial statement based on good audited financial report according to the criteria above (You are required to hold a financial/accounting degree or CFA)

B. Paid $50 per 100 audited financial statement just based on Jakarta or Bali location financial report according  (easier)";Data Extraction
"I have carried out some measurements.

I need to develop a prediction model. 

This is a regression project.

There is a need to carry out proper EDA and data cleansing

Freelancers must achieve certain score values (R2_score must be greater or equal to 0.85)


The freelancer must sign an NDA form before work commences. 

The budget is not a placeholder. 

There will be more opportunities to collaborate in future projects 

I need a quick turnaround for this. Say 2-4 hours";Machine Learning Model
"We are seeking an experienced Google Sheet expert to build a custom sales tracking sheet for a one-off project. The ideal candidate should have a strong background in creating complex Google Sheets with a focus on sales tracking and reporting.

Responsibilities:

-Collaborate with our team to understand our sales tracking needs and develop a customized Google Sheet solution that fits our requirements.
-Create and manage formulas, functions, and scripts in Google Sheets to automate and streamline our sales tracking process.
-Design and format the sheet to make it user-friendly and visually appealing.
-Ensure the accuracy and completeness of the data and troubleshoot any issues that arise.

Requirements:

-Proven work experience as a Google Sheet expert, with a track record of building and improving sales tracking sheets.
-In-depth knowledge of Google Sheets, including formulas, functions, and scripting.
-Strong analytical and problem-solving skills with attention to detail.
-Excellent communication and interpersonal skills, with the ability to work collaboratively with our team.
-Availability to work remotely and meet project deadlines.

If you have the skills and experience required for this job, we encourage you to apply. Please submit your resume, a brief cover letter, and examples of your previous work in Google Sheets. Note that this is a one-time project and will not require direct training of our team members.";Data Analytics
"If one day you want to be a top 0.01% data-driven PLG/UX/product leader, growth hacker, global speaker, influencer, content creator, entertainer, or start your own business or have your own YouTube channel, this is an opportunity for you.

At athenno.com we make entrepreneurship and commercial innovation accessible and successful for all on Earth.

This is an unpaid flex-time internship where you will be able to learn a lot about startups, commercial innovation, fundraising, consulting, being a digital nomad and traveling the world, working remotely, starting your own business, scientific and mathematical customer science, UX design, software architecture and engineering, data science, product management, philosophy of the law, administrative law and more.

If you are able to achieve results, then relationships can grow in any direction, including employment or partnership with a performance-based bonus/commission.

-

You will be assisting the Founder & CEO in different marketing, growth, content, community management, UX research, design, and other 360-degree product marketing management tasks.

Mandatory:

- You have strong moral values, empathy, curiosity, intuition, design, aesthetics and fashion sense, discipline, and a passion for people, stories, innovation, startups, data science, and technology.
- You are independent, competitive, creative, energetic, fun, results-oriented, precise, logical, and operational with strong common sense, thinkability, learnability, and attention to the smallest details, and you read and write hella a lot.
- Preference is given to minorities, students from poor backgrounds, ENTJ/INTJ/ENTP/INTP

Must have some of these:

- Basic experience in community management, education, content creation, YouTube/Instagram/TikTok, SEO, growth, PLG, networking, sales, lead generation, market research, business analysis, management consulting, pirate metrics, funnels, acquisition, and/or conversion.
- Basic knowledge of system design, flowcharts, UX research, UX laws, Figma design systems, Miro wireframing, innovation, entrepreneurship, continuous discovery, jobs-to-be-done, opportunity solution trees, tech startups, agile, lean, design sprint, etc
- Basic knowledge of tools like CRMs, Google Marketing Suite (Google Tag Manager, Analytics, Console, Data Studio, Ads, etc), Facebook Business, Canva/Figma, Squarespace/Wordpress, Mailchimp, Notion, Google Drive/Slides/Docs/Spreadsheets, and Miro.

To apply, besides sending your proposal here, send a good private message to Mev-Rael on LinkedIn, and think about what a ""good"" message should look like based on what you have read here and your thinking through.";LinkedIn
"I need to do an SEO audit and GA review for a site we're looking to grow.

Need to understand

Traffic
Conversions
Easy fixes SEO
GQA analysis for revenue improvement

And so on

Basically trying to understand the short and medium term fixes (if there are any) to increase revenue based on the high traffic.

Need analysis done asap.";Data Analysis
continue the work from before like i said we are nearly done;Data Science
Am looking for people who can analyse statistics  in my website the shortest time possible and help in distributing all activites for the company.;Data Science
"Dear Upworkers,

Our Scientific Research Company is looking for an Academic Researcher & Writer for the purpose of publishing several research papers in reputable academic journals. 

Please apply with your google scholar link if you have experience getting published in high ranking, reputable journals in any discipline that involves Mathematics, including Quantitative Finance, Probability Theory, Statistics, Physics, or other similar subjects.

The area of writing will be strictly related to Quantitative Trading systems & Strategy Validation & HFT & Execution & similar, related areas.

If you apply, we will send you a detailed briefing on how exactly to submit a proper research proposal with pricing, and get it funded by us.

Please note: you should be well versed with python based data analysis, have a basic knowledge working with financial time series, backtests, portfolio management and general subjects in quantitative finance. Please do not apply if these subjects are foreign to you, and you don't want to learn them.

If you work as faculty at a reputable institution or as reviewer at a reputable journal, that will be considered as a significant advantage when evaluating your application.

Please apply with confidence!";Data Science
"I have a list of 1000 company name.

I need.
Company Website
Founder
Facebook Page
Instagram Page
Twitter Page
CEO Email
Company Email";Data Scraping
"Dear all, we take part of a large event/exposition with an contact database (Market - Country - Company - Contact - Name,Function, Email).  We could manually go into the company list, see the employees of the company and copy their email; But we are looking for an automated service that does that and extracts all names, company and emails out of that listing. It's about 1500 contacts. You first have to login into the event intranet and you'll find the listing.";Data Scraping
"Not available at the moment
 Not available at the moment";Data Visualization
"We are looking for a computer vision expert to build a system that can detect the room type of indoor real-estate images. Examples of room type include living room, bedroom, bathroom, dining room and kitchen. Additionally, later on we would also need to detect objects present in the room (e.g., bed, sofas, dishes etc.)

The images would generally be of high resolution. We're flexible on the budget, and the main requirement is that the accuracy is very high.

Please share relevant experience while applying.";Machine Learning
"Requirements: -Set up Google Analytics (UA) and Google Analytics 4 in GTM; -Set up e-commerce tracking (revenue, transactions, quantity, refunds, add to cart, upsells) in GTM; -Set up Google Ads tracking (general tag and conversion tracking, where conversion is purchase) in GTM; -Set up Bing Ads tracking (general tag and conversion tracking, where conversion is purchase) in GTM; -Set up Facebook Pixel and Facebook Ads tracking (general tag and conversion tracking, where conversion is purchase) in GTM; -Set up HotJar in GTM; -Set up upsells tracking in GTM.";Google Analytics
"Job Position:   Data Analyst
Job Type : Full Time
Location:Remote
Job Duration:Minimum 6 months
Experience Required: 3+ Years

Responsibilities

•	Develop reports and dashboards from multiple datasources using 
a.	SQL Server Management Studio
b.	T-SQL
c.	Tableau Desktop / Tableau Online
d.	SSRS
e.	Report Builder 
f.	Visual Studio.
•	Perform complex data analysis to identify trends, perform reoccurring and ad-hoc business intelligence requests
•	Design, develop and establish KPIs to monitor analysis and provide strategic insights to drive growth and performance
•	Create user-friendly and dynamic Tableau dashboards with KPIs, Heat Maps, Scatterplots, Bar Charts, Slicers, Drill down, features with the understanding of when to use them
•	Develop standardized metrics to evaluate and benchmark as it pertains to short/long term resource planning and forecasting
•	Communicate complex analysis and insights to stakeholders and business leaders, both verbally and in writing
•	Address departmental analytics requests and facilitate needed data acquisition to support internal projects, special projects, and investigations
•	Establish best practices for Tableau reporting and dashboard development 
•	Administer and support a Tableau infrastructure including 
a.	Manage users, groups, licenses Active Directoryetc
•	Assess current state and identify opportunities for improvement 
•	Stay abreast of new Tableau releases and enhancements, and bring them into the platform and organization
•	Provide testing support for Dev,QA
•	Establish automated reporting and visualization exhibitsto analyze trends and patterns and improve data quality

Skillsets

•	Bachelors in Computer Science in IT or equivalent work experience 
•	3+ years Tableaurequired  
•	3+ years of SQL, including queries, stored procedures, functions, views
•	3+ years SSRS
•	Dashboard design, data reporting, and data manipulation tools 
•	Proficiency in MS Office suite (incl. Report Builder, PowerPoint, Microsoft Excel ,Access)
•	ETL using Microsoft SSIS, Visual studio or related tools
•	Ability to analyze complex data structures and SQL code with minimal direction

Payment will be done  via Upwork platform only. No direct hiring will be entertained.";Data Analysis
"We're a small team building a new kind of social network. We have pre-seed funding from silicon valley and are looking for a ninja neo4j back-end engineer to join our back-end team. 

Your responsibilities include working with a ~12TB dataset, importing it, creating relationships, building complex highly performant cypher queries, and exposing it through an API.

If you don't have experience working with large datasets on neo4j, you'll struggle with this project and would recommend against applying.

I'll share more details about the project in chat.";Big Data
"Extract the users and contributors of these 2 repos:
https://github.com/neo4j/graphql
https://github.com/neo4j/neo4j-javascript-driver

When you go to these links and then click on ""Used by"" on the right side, you'll see all the repos/usernames who have used this library before.
Also, if you go to Contributors on the right, you'll get the github usernames.

When you go to the profile of a user, you'll see their full name and email along with other information. Using the github username you should be able to extract the fullname, and email of the user. To do this task you could leverage PhantomBuster to get contributors, but need to figure out how to get users: https://phantombuster.com/phantombuster?category=github

To get emails, you could use PhantomBuster, or also using a tool like this to extract the email: https://github.com/paulirish/github-email

I want a CSV file with the following column names:
- Fullname (if available)
- Location
- Twitter/LinkedIn/any other links (if available)
- Email
- Which repo?
- Type (contributor or user?)";Data Scraping
"We are looking to create a custom website with a slick and professional design, and a special data visualisation feature. We don't want a dashboard, but we do want a creative way to display a number of varying opinions in one beautiful webpage. 

We will have a data set that will be regularly updated, and we want the website to pull through that data and visualise it on the website. 

The data will be mostly made up of text and people's opinions (similar to this https://upload.wikimedia.org/wikipedia/commons/6/65/Cognitive_bias_codex_en.svg?ref=insanelyusefulwebsites)

But we want it to be simplified and easy to understand quickly. 

The exact creative treatment of the data is yet to be established, but we would like applicant for this job to have clear examples of creative data visualisations that pull information from a live data set. 

To apply, please supply the following:
Examples of your work that showcase live data visualisation. 
Other examples of professional website builds. 

Many thanks.";Data Visualization
"I need several websites researched for a list of their providers.  The list needs to go to an excel spreadsheet. It is preferred to find the email address for each person on the website.  Here is a sample of a website:

https://www.aspenlaser.com/find-a-medical-professional/

I basically need healthcare providers listed on the websites.

Excel spreadsheet should include:

First Name
Last Name
Title (DC, MD, PT, DO)
Clinic Name
Clinic Address Line 1
Clinic Address Line 2
Clinic Address Line 3
City
State
Zip 
Country
Phone
Fax
Email
Website";Data Mining
"Title: Deep Space Artificial Intelligence Engineer

Job Description:

We are seeking a skilled and experienced Deep Space Artificial Intelligence Engineer to work on our cutting-edge project for early asteroid prediction. As a part of our team, you will be responsible for designing, developing and implementing AI algorithms that will enable accurate and timely detection of asteroids heading towards Earth.

Responsibilities:

Collaborate with a team of researchers and engineers to design and develop AI models for early detection of asteroids.
Implement and test algorithms to improve the accuracy and speed of asteroid detection.
Evaluate the performance of the models and optimize them based on the results.
Use big data techniques to process large sets of data and develop models that can handle real-time data streams.
Communicate the results and findings to the project team and stakeholders.
Requirements:

Strong experience in AI, machine learning, and deep learning.
Proficiency in programming languages such as Python and Java.
Strong understanding of data analysis and statistics.
Familiarity with big data technologies such as Hadoop, Spark, and NoSQL databases.
Experience working with real-time data and developing models for time series data.
Strong problem-solving and critical thinking skills.
Excellent communication and team collaboration skills.

Preferred Qualifications:

Experience in the field of space science and exploration.
Experience with satellite data processing and analysis.
Experience with data visualization and presentation.
Location: Remote or Onsite (if feasible)";Data Analysis
We need help to work with specific PostGIS related issues, but we are looking for an expert to be available throughout the year to help with proper implementation and usage;Geospatial Data
"Dear Upworkers,

Our Scientific Research Company is looking for an Academic Researcher & Writer for the purpose of publishing several research papers in reputable academic journals. 

Please apply with your google scholar link if you have experience getting published in high ranking, reputable journals in any discipline that involves Mathematics, including Quantitative Finance, Probability Theory, Statistics, Physics, or other similar subjects.

The area of writing will be strictly related to Quantitative Trading systems & Strategy Validation & HFT & Execution & similar, related areas.

If you apply, we will send you a detailed briefing on how exactly to submit a proper research proposal with pricing, and get it funded by us.

Please note: you should be well versed with python based data analysis, have a basic knowledge working with financial time series, backtests, portfolio management and general subjects in quantitative finance. Please do not apply if these subjects are foreign to you, and you don't want to learn them.

If you work as faculty at a reputable institution or as reviewer at a reputable journal, that will be considered as a significant advantage when evaluating your application.

Please apply with confidence!";Data Science
* Develop and implement reusable architecture of data pipelines including Machine Learning and Analytics. * Work comfortably with structured and unstructured data in programming language SQL, R, Python, Java. * Understand meta-data management system and designing pipelines. * Exposure to AI/Model development;Data Science
"We are looking for someone to create crawl dashboards for our SEO clients. The requirements are:
- Set up an automated weekly Screaming Frog crawl
- Data to be visualised in Google Data Studio (Looker Studio)
- Export of specific reports, for example All redirects, 404 inlinks

Must have experience and knowledge of SEO stats, Data Studio and Screaming Frog.

Please submit an example dashboard for such project you have created in the past.";Google Data Studio
"We require a data scraper, who can scrap data of Influencers and show us the below-mentioned points from social media platforms Instagram, TikTok, Facebook, and youtube. We need to show this data/matrices in our upcoming Product SaaS

1. Full Name 
2. Profile Image 
3. Country
4. Bio
5. Followers count
6. Recent 20 posts
7. Avg Post Views
8. Engagement Rate
9. Gender Ratio
10. Audience age by gender in %
11. Audience location in %
12. Average Comments
13. Average Likes";Data Scraping
"Immediately Hire and needs to complete before this weekend.
These are the following tasks. Done is already completed, and Not Done needs to be completed.

1. Create data sets for training (already created)
• Semantic labeling: Nodes shall be labeled by their semantics, e.g., adder, multiplier,  multiplexer, etc. (Already worked)
• Inferring hierarchy: Nodes belonging to the same submodules shall be labeled  and  the hierarchy among submodules shall be extracted (Already worked) 
2. Explore GNN architectures for semantic inference (is not done) 
• Determine possible input layers for representing the circuits 
• Determine how subcircuits that are parts of larger circuits are extracted for inference.
3. Benchmarking (not done)
Immediately hire. The attached paper is the reference. Rar file is the source and the main working file name is circuitDatasetCreation.py.";Python
"Hi, 

I am looking for someone to crawl Google's top 50 results, and top 50 results in Google Shopping, of 4,000 keywords.
The data I need is the domain(or full url), and what ranking it was, and what keyword. 

Looking for a quick turnaround time.";Data Scraping
We're looking for an analyst to help us add new Retool and metabase dashboards for our growth and internal ops teams. We have the resources set up, so it's really more about writing a few queries in SQL and making sure the dashboards are intuitive for them to use. Part time, but recurring work, that usually needs to be responded to within 24 hours.;Data Analysis
"We need someone to create and deploy an NLP engine that will injest email text and let us know if the email is an out-of-office email or not.

In addition to that it needs to let us know through data parsing when the person who replied will be back in the office.

The code needs to be accessible via an API call, and needs to deployed into an AWS environment";Data Scraping
I am looking for a machine learning expert to develop a toolkit which creates templates (output) based on existing reports it has been fed (input). For an MVP I would like to use several reports of a specific document type (to be defined) used in a highly regulated field ( medical device, pharma);Data Science
"2. Target Audience + Context 15 %
Describe the target audience and the context . In case of datasets 2 and 3 you can imagine about it.
In the description you should answer questions as : Who they are? , what kind of decision do they take
in daily routine? what kind of “problems” can they have? what they can “need” to get better
performance ? Summarizing what will be interesting to get answered using your datasets to provide
business insights. The 5W1H scheme can help. Be aware that sometimes, you can’t solve all the problems or needs completely
.
In short, it is a question of understanding the mental model of users so that you can design dashboard or data visualization products adapted to their objectives, abilities and the context in which they will be used.

3. EDA – Exploratory Data Analysis 15 %
Explore dataset with descriptive analytics to understanding of the data (for examples calculating some statistics like mean, median, quartiles, box plots, scatterplots....) And extract some previous ideas for hypothesis.
4. SPSI – MECE 20%
Apply Situation , Problem. Solution, Impact (SPSI) create, and validate your initial hypothesis with MECE logic tree. Define and formulate the problem you want to solve, and explain it briefly.

5. Storyboard & KPI 15%
Applying dashboard storyboard , KPI Snapshot , Trends , Actions (this one optional) define your KPI and possible charts
6. Sketch/wireframe and visuals 10 %
Sketch you visuals and design you dashboard layout (minimum one page) and
visuals ( you can do it by hand or using Miro o Moqups) It will be appreciated if you
show how you will display the same data in 2 o 3 different chart types, for the desire
7 . Create your dashboard or visualization 15 %
Using Power BI or Google Data Studio. create a basic report/dashboard showcasing
the designed dashboard. ( minimum one page).";Google Data Studio
"I have a google sheet that i am using to create some measurable KPI's for our sign printing factory.

I am wanting to create a good visual, attractive dashboard in order to display this data real time on app or online dashboard for the production and management to keep eye on.

Monthly setup will mean going into the sheet - entering dates, sales targets & clearing out the old months data
these fields are indicated in blue

At the end of each day - the production manager will take the data from the print production system and enter to the sheet. 
this is the 2 fields - MTD completed figure and the current WIP (Work in progress) figure. 

As the month runs down - the production days in the month are less and the average per day required to manufacturer is calculated - based on the target

the key figures we want displayed is:
- Sales required to hit target
- Production Work required to hit target
- Average per day required to hit target
- Total MTD completed 
- Total WIP Balance
Also - a graph of each days production - bar.
xls file attached.

thank you";Data Visualization
"Need someone who is really familiar with how to show the data in a proper way and show the connection between data. 

It is a report instead one sheet with a few tables or bar charts (text part would be done myself)

Need someone who is really proficient in this field in stead of just knowing how to use these tools

Open to negotiate. And kindly connect for more details. 

It is more of a report to complete instead of only output several tables.";Data Visualization
"Job Title: Front-End Developer (React) 
Company: Othentic 
Location: Remote

We are seeking a highly motivated and skilled Front-End Developer with expertise in React to join our start-up, Othentic. Our company is building a cutting-edge platform that enables the management of mutable metadata for NFTs and Soulbound NFTs by facilitating complex data streams from on-chain and off-chain data sources.

Responsibilities:
* Develop and maintain front-end components using React and related technologies
* Collaborate with our back-end team to design and implement user interfaces that communicate with our platform's API
* Work closely with our product and design teams to translate requirements and wireframes into high-quality user interfaces
* Ensure our platform's front-end is optimized for performance, usability, and accessibility
* Participate in code reviews and maintain code quality and integrity
* Stay up-to-date with the latest front-end development trends and best practices
Requirements:
* Proficiency in React, JavaScript, HTML, and CSS
* Experience with state management libraries such as Redux or MobX
* Familiarity with front-end build tools such as Webpack, Babel, and Gulp
* Ability to write clean, maintainable, and well-documented code
* Excellent problem-solving and debugging skills
* Strong communication and collaboration skills
Preferred qualifications:
* Bachelor's degree in Computer Science, Engineering or a related field
* Experience working with blockchain and/or NFTs
* Familiarity with TypeScript and Next.js
* Knowledge of UI/UX design principles and experience working with design teams

If you are passionate about front-end development, have experience with React, and are excited about building innovative products, we encourage you to apply to this role at Othentic.";React
"SCOVR is a native App for iOS and Android.
With Mixpanel we would like to measure our North Star Metrics to win new investors.

We are looking for a Mixpanel Certified Expert that is able to integrate Intercom: https://www.intercom.com/app-store/?app_package_code=mixpanel

We are in SCOVR-Beta currently: https://www.scovr.com/waitlist/join-beta
Who we are: www.amvlet.com/about";Google Data Studio
"Consider a manufacturing plant that produces high-quality products primarily using skilled labor. They are concerned about defects found in the surface coating for their product and have been provided a dataset containing quality ratings for a sample of products. Note that each prompt below may require more than one visualization and/or analysis to fully answer.
1.	Conduct an initial exploration of the data and summarize any key features. This must include, but is not limited to, 1) descriptive statistics, 2) features of the response variable, and 3) identifying any limitations of the dataset such as missing data or outliers.
Note that this evaluation should include some visual exploration of the data (i.e., histograms, box plots, scatter plots, etc.).
2.	The current performance target is a quality rating of 85.0. Do the data suggest that they are currently meeting this requirement?
3.	Is there a significant difference in the average surface quality ratings for products produced on each of the two Production Lines?
4.	Is the variation in surface quality consistent across the two Production Lines?
5.	Observations showed that employees were using different methods to apply the surface coating. Are there any significant differences in the resulting quality ratings from each of these methods?
6.	They currently have four teams of employees with different levels of experience that affect the quality of the products they produce. Is there evidence that there is a significant difference in the average surface quality ratings for products produced on each of the two Production Lines when controlling for the differences in teams?
7.	What conditions (i.e., combinations of Line, Team, and Method) are associated with the best and worst product quality ratings?";Minitab
"I wanted to see if you can build visually appeal excel calculator.  

See attached spreadsheet.   

First is an example of what the calculators could look like. The buttons to click on. There would then need to be built a visually appealing input page.   

Second the number of calculators needed.   

Three the formulas.   

Then I will need to results page. Bearing in mind one result will show at a time.";Data Visualization
"We are looking for someone to help train a model to extract 4 potential values from a set of standardized images. 

The model needs to be trained, we can use scale.com to help with the image labeling.

Afterwards, an API needs to be exposed which allows images to be passed and in return the extracted values to be returned. 

Please provide an example of previously similar projects, you estimate to on time required to complete this tasks and budget.";Machine Learning
We are seeking an experienced ChatGPT Web Application Integrator to join our team. The successful candidate will be responsible for integrating the ChatGPT AI model from OpenAI into our web application. This includes configuring and optimizing the model to work seamlessly with our platform, as well as developing new features and capabilities that utilize the model's natural language processing abilities. All the background and requirement includes: 1. fine tuning the ChatGPT with downstream task in our specific area. 2. more question specific and iterative improvement the discussion performance. 3. Analysis the user's intention during chat;Generative Adversarial Network
train chat gpt. for swisstravelchat.com with attached data;Node.js
"Data Miner

Key Duties will include:
• Identifying suitable distributors, wholesalers, retail chains, e-commerce platforms, individual stores in international markets and other companies in various markets can be found. 
• Extracting data from google, google maps, websites and formatting the data in a way that is easy to read.   

Other Duties at times. 
• Building a database of suitable channels with excel and if possible, finding the correct decision makers contact details such as name, position, email address.
• Making a list of influencers, media publications in each market.
• Data entry
•Reaching out to stores, retailers, distributors via email then updating the CRM.

Desired:

• 2+ year experience in a lead generation/Data Extraction role.
• Strong understanding of retail, distribution, consumer goods and FMCG or tech sales.
• High level of both written and spoken English.
• Basic level of knowledge with Excel/LinkedIn
• High level attention to detail.
• Experience in the health, beauty, wellness, skincare categories.  


This role is long term/ongoing and could become full time work for the right applicant.

High Attention to detail is a must!!!!";Data Mining
"To support on Data Science Academic guidance
1) Must hold a doctoral/Masters degree in Data Science 
2) Experienced problem-solving for exam guidance and relevant modules in Data Science.";Data Science
we have GPU processing system and the data coming is for CPU processing ...we need to switch the data to be processed buy GPU ..we need to encrypt the data that coming from XMR coin to be processed by GPU so our new software will encrypt the data in away that can be handled by GPU and then DECRYPT the data to return the results knowledge by data encrypting and decrypting  using latest technologies to do so is important and most ..second knowledge of crypto algorithms is important also ...we are dealing with data called RANDOM X  ...from XMR COIN ..THANK YOU;Data Mining
"We need ongoing help with producing financial + subscription revenue reports using Stripe Sigma.

Our immediate need is a New MRR report by month and week.";Operations Analytics
"I am a professional magician & illusionist seeking a data scraper to find names & emails of primary contact persons for specific events.

Pay: $0.25 per lead up to $100 for this project.

Deliverable: Specifically, I need the data found to be formatted in a google sheet with three columns: name, event, and email address for primary contact persons.

Details:
Event Locations: 
Charlotte, NC area

Event Dates: May-December of 2023

Types of events looking for:
1. Business conferences/expos/conventions
2. Fundraiser galas
3. Community events/festivals

Happy to answer any questions any applicants may have.";Data Scraping
"Greetings Upworkers!

Do you speak verbal English?

Live to provide solutions?

Task: Scrape data from the web, push the data to new web page.

1 # Full support till perfect 

2# Best practices 

3# Happy with deadlines

4# Confirm the times you are online

5# If you don't answer the questions raised in the job posting, it is likely you won't get a reply from us.

6# You should be able to create video i.e. via loom to show your code working. 

To fast track your application, please do send a video recording via a cloud URL, not google drive, you can use loom or dropbox capture. 

Budget: 10 USD, not hourly, not a placeholder. 

Look forward to working with you on many gigs.";Web Scraping
"We are looking for someone with experiencing scraping websites.

We have a list of car dealership sites that we want to scrape the search results for.

The solution must be written in Python and it should live as a DAG in Airflow.";Data Extraction
I would like to use NLP to generate thematic codes for interview transcripts.  In the past,  I have generated these codes myself via Nvivo and Atlas.ti. It's my understanding we can now leverage ML to do this instead.  I would like someone to provide working code in R that would generate codes as a result.  I can provide dummy text for training if necessary. My hope is to receive the working code, then I can edit it as needed to run analysis on my transcripts.  Deadline is Wednesday 12 PM CT.;Data Science Consultation
"We are looking for a skilled Python developer to extract data tables from three complex Excel sheets and design a database to store the extracted data. The successful candidate will be responsible for developing Python scripts to extract data tables from the Excel sheets and organize the data in a suitable format for storage in a database. They will also need to design the database schema to accommodate different data fields and ensure that the data is stored efficiently and effectively.

Responsibilities:

Develop Python scripts to extract data tables from three complex Excel sheets
Organize the extracted data into a suitable format for storage in a database
Design and develop a database schema that accommodates different data fields and efficiently stores the extracted data
Deploy the database schema";Data Extraction
"Looking for a solution to track, monitor and review staff performance for our onboarding process. The process helps induct members into a fitness health assessment process of 2 x 1-hour session with a personal trainer.

The flow of the process is
1) Add members data (name, start date, allocated trainer) to a tracker
2) Assign dates & time for each member advising when the sessions will take place
3) Have a section that can mark the session as completed or still pending with conditional formatting to an outcome
4) Identify what the outcome of both sessions were (Choices are: Sold Package, interested/follow up required, unable to close) 
5) If a member was sold a package, what package was sold (5ss, 10ss, 20ss, 30ss, 50ss, 100ss, other)
6) section for comments
7) if no sale was made during the process an automatic follow up appointment needs to be calculated 9-week from the date of No sale
8) Create a tally/dashboard of how many sessions booked, how many completed by each trainer per day/week/month, advising the sales closing ratios, unattended session, session remaining, bookings to take place each day  

We would like this to be editable so we can add member, different packages and different trainers.";Data Analysis
We need data migration from Cobol to Excel it can be huge data or it depends.;Data Migration
"We are looking for a passionate certified Data Analyst. The successful candidate will turn data into information, information into insight and insight into business decisions.

Responsibilities
1.Interpret data, analyze results using statistical techniques and provide ongoing reports.

2.Develop and implement databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality.

3.Acquire data from primary or secondary data sources and maintain databases/data systems.

4.Identify, analyze, and interpret trends or patterns in complex data sets";Data Mining
"We are a software company specialized in quantitative trading of major cryptocurrency derivatives, primarily options. 

In this project, we aim to explore the feasibility of building a price volatility prediction model of cryptocurreny assets over a specified tight window of time, for example 12-48 hours. 

In this project we hope to build a proof of concept prediction model to understand the following:

1. What data corpora are needed to be successful?
2. How accurate can we theoretically expect to be over time windows of 1 hour, 8 hours, 24 hours?
3. What infrastructure (eg storage, cloud compute, etc) is required?

Note that we have data engineers on staff who will support this project and our expectations are relatively modest. Essentially this is a R&D project. 

If the PoC demontrates likely future value, the engagement may extend to a longer-term contract.";Machine Learning Model
"I am looking for a research analyst who can support a project i am working on that has tight timescales and is to be delivered by early March.

The work will involve engaging with employers, education and training providers and service users  in a specific location using defined research questions. This is an area that has a high proportion of SME's. 

The demographics of the location is very diverse, there is also socio economic challenges with deprivation and in work poverty. 

The purpose of the research is the understand the views and opinions on the  local council's proposed strategy to Post 16 Skills and Employment Skills and Enterprise. 

We want to make sure residents have the right skills and qualifications needed to land good quality jobs in the borough. Gain employer insights to help identify current skills gaps and ensure focus is in the right areas to address barriers to recruiting for roles.

Research Analyst Responsibilities:

Conducting secondary desk research and understanding the context and work of other local boroughs.

Identifying and analysing trends and forecasts and recommending improvements.

Conducting surveys, interviews, collating quantitative and qualitative data from secondary and primary data sources.

Active engagement with the  employers - private, public and voluntary and charity sectors. Further and Higher Education providers, including skills and training and service users.

Using data analysis and interpretations to guide the decision-making and recommendations.
.
 Using statistical, economic, and data modeling techniques to develop graphs, charts, dashboards and insights and presenting findings

Providing recommendations and insights from the research to develop into a report.

Organizing and storing data for future research projects.

Research Analyst Requirements:

Education and Experience in applied research or data management.

Strong mathematical, analytical, and data modelling skills.

The ability to manipulate  data sets into manageable, understandable insights and reporting.

Excellent problem-solving, communication and team-working skills.

Familiarity with data modeling software and Excel software.

Attention to detail and organizational skills.

THIS WILL BE A FIXED PRICE JOB";Data Analysis
• Data Architect • Project: bank • Only Citizen of European Union / Passport EU holder (no relocation no) • Long term period • 100% remote • 5+ years' IT-related professional experience, preferably Information and Data architecture, Business and/or System Analyst roles • Practical experience working with modelling tools: Sparx, EA, Erwin etc) is a must • Basic knowledge of Data Governance/Metadata managements and Master Data tools (TBD) • Conceptual and logical thinking • Strong analytical skills and attention to details • Good communication skills • Ability to express opinion in verbal, written and model-driven forms • Ability to see holistic picture and ability to deep-dive into details as necessary • Ability to accept uncertainty and ability to make decisions with limited information • Willingness and ability to learn and deal with large amount of information • Higher education in Information Technology preferred • Fluent English is required in spoken and written communication. • Daily activities: • Contribute to Data Architecture modernization and practice enhancement • Participate in developing and improving data architecture and modelling standards, guidelines, and principles • Partner with the business stakeholders in understanding and translating business requirements into data architecture artifacts – models, blueprints, specifications • Coordinate business data modelling work of other internal or external data modelers • Organize and lead data modelling workshops with the Data Owners, Data Stewards, and business subject matter experts • Support projects & IT development teams in logical and physical data modelling, data architecture decisions, etc. • Validate the application data models according to the business requirements, established design standards and the best practices • Support various Metadata and Master Data management initiatives;Data Analysis
We are developing an MVP for a US client to analyze 1000 medical images using Deep Learning and integrate it into a Mobile Application. No need for classification of images or annotations. Only Image analysis required.;Data Analysis
The project is about an AI tool that could analyze a user's transactions and identify them as taxable or nontaxable transactions based on Italian Tax Law. As far as I'm aware, there are no public datasets available, so they'd needed to be made from scratch, with sources only from books. Would need consultation & planning before starting the project.;Data Science Consultation
"I need a Data Scientist with Statistics background that has an extensive experience in the Insurance Industry. 
The candidate should have the following skills:
- Python
- R
- Azure Machine Learning
- Snowflake
- Github
- Databricks
- MLFlow
- Preferrably worked with clients in AU, US, or UK

The job is to act as a consultant if I have stats/machine learning/data science related questions. This is for a long-term engagement.";Data Science
Looking for professional to take an existing project to the next level with slick visualization and leverage embedded PowerBI capabilities to provide a easy to use experience for the end users.;Data Visualization
Please see attached files for instructions. Need help with hw;Data Analysis
"Need to Work on a software Proejct, which needs the following skills:

NLP | Web Scraping | Social Media Feed Analysis";Data Science
"I've got 4 websites for my client, each of which they want to pass back product information to GA4 for

https://docs.google.com/spreadsheets/d/1xCtK1tZsWnDFWZ8lGILIqKvGGyHSu7BcXqB2H9GpQKc/edit#gid=0

check the ""Website"" column in the ""Transition Checklist Tab"". the products to pass back for each are identical and the site set up should be pretty much identical. I would like to complete this project for $200 or less.";Google Tag Manager
"I'm looking at building the following AI tools:
- AI game
- AI based decision making tool
- AI bot for a therapist/friend/coach
- AI does custom market research for a business

Each tool above has its own features and we will be using already existing AI tools to package this";Artificial Intelligence
"Get all city names into a json file from a example website below. Nothing more data is required as its a simple scraping job. Hence the budget is $10, 

https://www.censusindia.co.in/states/karnataka";Data Scraping
Build and train the model with our own data so it can generate text that simulates a conversation with a customer, providing information and assistance as needed.  We dont have a lot of data so this should be fairly easy. We expect customers to enquire about our loan rates, types of products we offer, what are fees are, what their loan terms would be. Most(if not all) of this info is already on our website www.instalend.com;AI Chatbot
"1-2 month engagement.
~10 hrs/week

We are a Health & Fitness Mobile App technology company looking for a talented and motivated Mobile Ad Attribution Specialist to join our team. As a key player in our marketing efforts, you will be responsible for tracking and analyzing the performance of our mobile advertising campaigns to drive growth and optimization.

Responsibilities:
-Implement and manage mobile ad attribution tracking solutions across various mobile platforms and advertising networks.
-Analyze and report on the performance of mobile advertising campaigns, including impression, click, conversion and return on ad spend data.
-Work with the marketing team to develop and execute campaign optimization strategies, including bid adjustments, targeting, and creative optimization.
-Conduct deep-dive analysis on campaign performance, identifying trends, opportunities for improvement and making recommendations to the marketing team.
-Collaborate with cross-functional teams, including product, engineering, and customer success, to ensure accurate tracking and reporting of mobile ad data.
-Stay up-to-date with the latest developments and trends in mobile ad attribution and regularly recommend new solutions or technologies to improve tracking and analysis.

Requirements:
-At least 4 years of experience as a Mobile Ad Attribution Specialist or similar role.
-In-depth understanding of mobile ad attribution methodologies, such as last-click, first-click, and multi-touch attribution.
-Strong knowledge of mobile ad platforms such as Google AdWords, Facebook Ads, Apple Search Ads, etc.
-Excellent data analysis skills, using tools such as Google Analytics, Tableau, or similar solutions.
-Strong problem-solving skills, with the ability to identify issues, develop solutions, and implement changes quickly.
-Attention to detail is a very important suite for us so start your application with the keyword ‘Attribution’ to have your application considered.
-Excellent written and verbal communication skills, able to communicate complex data and insights to stakeholders.
-Bachelor's degree in Marketing, Computer Science, Statistics, or a related field.

This is a great opportunity to join a dynamic and fast-paced team and play a critical role in driving the growth of our company. If you are passionate about mobile advertising and data-driven decision-making, we would love to hear from you.";Mobile Marketing
"Hi, in this project - we are dealing with abstract values such as color and design. 
I have the below datasets

Historical dataset
 - Image File - 
(1) Product Image (Abstract Color and design)

- in .CSV Format - 
(1) Product Image filename
(2) Product Brand
(3) Product Country of origin
(4) Product Selling Price
(5) Duration product has been in the market (months)

And would like to create a model to analyze future products via the same dataset.
The only value we won't have for a new product is (5) Duration product been in market, as the value would be 0

Examples of abstract images has been attached";Data Analysis
I need help to Predicts of winners in NBA games using linear regression, Using Python. i will share more details in the chat.;Python
"Looking for a basic demo of Azure Machine Learning Capability.

Sample can either be;
- Structured: tabular (table-like) data (e.g. SQL table) 

OR

Unstructured data via PDF or Microsoft Word documents.

** There is scope in the future to feed the output of machine learning into Azure OpenAI GPT-3 to obtain a linguistic (chat-like) response **";Data Science
"1. I have data in PDF Forms (which I can share later). There are two type of PDF forms, the data within each PDF type has similar layout and structure. 
2. Fine-tune a LayoutLM V1 model on those PDF forms data. The objective is that the model should be able to identify sections within the PDF documents. after we have trained or fine tuned on our custom data.

 Important: Use of data annotation tool is not allowed. The training data generation need to be done in python. This is a key ask.

3. After fine tune generate performance metrics. The F1 score should be high above 80%.
4. When tested with new documents coming from type1, type2 it should detect the sections correctly.

*You can use other model like Donut/LitLM to achieve the above. But it should be licensed to be used for commercial purpose.";Natural Language Processing
"Hello! 

We are looking for an individual who can help us compile a database of motivational videos and clips from various sources such as youtube interviews, podcast clips, instagram reel videos etc. 

We simply need them pulled and put into one large database such as google drive or something similar. This is certainly something that we will continue to do often so doing well can land you good job flow and a s other opportunities arise within the business and trust is built, you will be the first we turn to if those particular jobs fit your skillset. 

I look forward to working with you!";Data Scraping
"Looking to fine-tune an OpenAI classifier engine with 12-20 categories.  Please note: have limited training data, though there will be low variance of inputs.

Part of deliverable will be producing enough training data to achieve robust classification.";Data Science
Now the goal is to make a ML model of sematic clustering. In the first step, you will do semantic clustering with the help of text embedded model. Maybe it will a pre-trained model. Then I could give you a manual clustering with text to train the model to see how much the model accuracy increase. Then you could test the model with rest data (10% data).;Data Science
"I want to create a tool for my clients that will allow them to ask question to an AI using NLU and the AI will retrieve the correct information. Here is an example of a use case: 

A client has a Kajabi course teaching Pharmacists how to build an income by offering remote patient care. Course topics include: 

1. How to market to physician offices 
2. How to onboard new clients 
3. How to set up your medical data system 
4. How to bill clients each month 

A client wants to ask, ""what are the best medical data systems I should use?"". So they go to our helpful ""AI-concierge.""

The instructors of the course have answered that question inside of a 60 minute call. The call recording and transcription is uploaded and available in Kajabi. 

The customer types into the AI Concierge, ""what are the best medical data systems I should use"". and it responds with, ""Take a look at this video around the 17 minute mark where we discuss the best media data systems to use"" 

I don't know the budget or what it would take to actually build an AI tool that could do this for my client (and others clients) but I would love some proposals. 

Please ask any clarifying questions.";ChatGPT
"Hello! I want the job boards of the companies on Forbes Cloud 100 (https://www.forbes.com/lists/cloud100) added to a single Airtable table with each open role having its own row.

Each row should have relevant columns for the role including (but not limited to): Company (e.g., Stripe), role (e.g., Account Executive), team (e.g., Sales), location (e.g., San Francisco), link to the role, and any other columns that might be relevant.

This data should be refreshed daily with new roles added and roles that are no longer on the job boards removed,

Would like this delivered with 2-3 weeks with async feedback sessions along the way.

If this works out, I have similar projects that I would like executed.

Looking foward to hearing from you!";Data Scraping
"I am aiming to reproduce the paper: Learning Representations and Generative Models for 3D Point Clouds with PyTorch (original code uses Tensorflow).

https://arxiv.org/abs/1707.02392

https://github.com/optas/latent_3d_points

I already have my GAN and a data loader, but it's not working well.  The deliverables would be a python script for training the GAN with 3d point clouds and a script for new point cloud generation. You can use the code I already have if you want, maybe you can even find and fix my bugs (generation of shapes is plain noise). I can provide you with the datasets too.

The final goal is to generate somewhat good point clouds for different shapes.";PyTorch
delivery in 24hours , sas viya studio analytics. my name is ahmed , if you have any other questions please let me know i will explain them;SAS
Merge two datasets using fuzzy string matching. Can be done using any language – Python, R, etc. One of the datasets is available in RDF Dump Files. It needs to be extracted to txt/csv format. The size of the dataset is 1.2 TB.;Data Science
"I need a list of all the exhibitors with certain attributes from the website below.

https://ambiente.digital.messefrankfurt.com/exhibitor-search/

The attached excel shows the attributes needed for each exhibitor.";Data Scraping
I would like to invite you to complete SHL General Ability Test, thanks!;Data Analysis
"Hi, we have implemented the MRNet to classify knee MRIs (https://stanfordmlgroup.github.io/competitions/mrnet/) and gathered a private set of MRIs that we want to classify, but the results we have are not optimal. We are looking for a python developer that help us with the optimization of the CNN accuracy, recall and precision. Also we need to implement a visual representation of the attention map of the models (https://stanfordmlgroup.github.io/projects/mrnet/). The activities to do are:

1. Increase accuracy, recall and precision of the net in our private data set
2. Output attention heat map for visual aid

We would also need a complete report of the findings and results of the implementation in terms of accuracy and ROC using cross-validation techniques";Computer Vision
"Developers Job

We are looking for an analytical, results-driven back-end developer who will work with team members to troubleshoot and improve current back-end applications and processes. 

The Back-end Developer will use his or her understanding of programming languages and tools to analyze current codes and industry developments, formulate more efficient processes, solve problems, and create a more seamless experience for users. 

To succeed as a backend developer, you should be focused on building a better, more efficient program and creating a better end-user experience. You should be knowledgeable, collaborative, and motivated.

Developer Responsibilities:

Compile and analyze data, processes, and codes to troubleshoot problems and identify areas for improvement.

Collaborating with the front-end developers and other team members to establish objectives and design more functional, cohesive codes to enhance the user experience.

Developing ideas for new programs, products, or features by monitoring industry developments and trends.
Recording data and reporting it to proper parties, such as clients or leadership.

Participating in continuing education and training to remain current on best practices, learn new programming languages, and better assist other team members.
Taking lead on projects, as needed.

Developer Requirements:

Bachelor’s degree in computer programming, computer science, or a related field.

Experience may be required.

Fluency or understanding of specific languages, HTML, CSS, Javascript, MySQL

Prefer React, React Native

Strong understanding of the web development cycle and programming techniques and tools.

Ability to work independently or with a group.
Willingness to sit at desk for extended periods.

Note that this is an ON-SITE WORK around Pasay City Metro Manila.";JavaScript
I have very limited coding experience, i would like to have a tutor/ coach that can teach me the basics so I can complete the Deep Learning for coders with fastai & PyTorch course by Jeremy Howard.. The course includes learning python, Jupyter notebook, PyTorch, and fastai.;Data Science
"Data Analyst/Data Scientist for Contact and Company Deduplication

Description: We are seeking a skilled data analyst or data scientist to help us deduplicate a large list of contacts and their associated companies that are stored in two different spreadsheets. 

The list contains many accounts that are duplicates and may have different variations of the same name, such as XL Broadband, XL Broadband Inc., or XL Broadband, LLC. We need someone who can identify and merge the duplicates while maintaining a high level of data integrity.

Responsibilities:

Analyze and clean up large datasets to remove duplicates and merge similar entries.

Use tools such as SQL to handle the task.

Verify the accuracy of the deduplication process and maintain data integrity.

Communicate with the project manager and provide regular progress updates.

Requirements:

Proven experience as a data analyst or data scientist with experience in data cleansing and database management.

Strong knowledge of SQL and data analysis tools.

Excellent attention to detail and the ability to maintain high levels of data accuracy.

Effective communication and project management skills.

To apply, please submit your proposal, including your experience with similar projects, your hourly rate, and your estimated timeline for completion. 

I have attached two sample files so you can see what we are working with.";Data Analysis
"We're looking for a developer to create a Python script and deploy it over an API such as FastAPI or Flask that takes an article URL as input and extracts relevant HTML elements from it. The script will then separate the HTML elements into distinct categories such as image, caption, paragraph text, heading, etc. Finally, the script will return the extracted content through an API endpoint.

Requirements:

Strong experience in Python development.
Familiarity with HTML parsing and data extraction.
Familiarity with FastAPI or Flask and deploying scripts to an API.
Ability to deliver high-quality, clean, and maintainable code.
Strong communication skills and ability to provide regular updates on progress.
Deliverables:

Python script that extracts content from an article URL.
API endpoint that returns the extracted content in a JSON format.
Well-documented code with clear instructions on how to run the script and modify it if needed.
Testing and quality assurance to ensure the script works as expected.

Example JSON format is attached. The JSON attached is NOT what is expected from this job, as you can ignore the summarization and highlighting parts. 

Timeline:
We're looking to complete this project within the next two weeks. The ideal candidate should be able to start working immediately and commit at least 4 hours per week to this project.

Budget:
Our budget for this project is $100, but it's negotiable based on the candidate's experience and expertise. Please submit your proposal with a full quote for the project, examples of similar projects you've completed in the past, your estimated timeline, and your hourly rate if applicable. Most importantly, READ THE JSON. To be considered, you must include the word at the top of the json at the top of your proposal. Only those with this word will be considered.

If you're interested in this project, please submit your proposal. We'll review all proposals and contact the most qualified candidates for an interview.

Note: this is the first part in a two-part project. We would prefer to work with the same engineer for both parts, dependent on good results with the first";Data Mining
Looking for a faculty  who can start immediately to teach Microsoft Power Bi on weekly basis with a contract length of 3 to 6 months;Microsoft Power BI
"Hello,
We are looking for someone that is well versed in conversion rate optimization and has the skill set to A/B test website, call actions, workflow etc to better the business bottom line. For now its a one off task but we would love to use you for future projects! If this is something you have done before, lets chat. 
Thanks!";A/B Testing
"We are a small high-tech company that provides face-to-face and online training courses and consulting in machine learning and other topics using Python.

You are an experienced Django developer who would enjoy expanding and improving our existing company website backend, which is based on the Django Mezzanine CMS. You will initially be responsible for making the booking system more flexible, adding support for multiple timezones and currencies, improving the Xero integration, and making various other improvements and fixes.

The estimated project period is 1 month. If the project is a success, we would like to hire you for some larger Django-based projects involving data science.

More detail:

You must be highly experienced with Python and Django, integrating with web services via APIs (like CRM, Xero, Stripe, marketing automation APIs), working with Unix systems, and preferably with Mezzanine, PostgreSQL, and Ansible. You must also have a strong sense of best practices in Python for maintainability, and project management skills using GitHub.

To fit the role you will:

- Have the ability to communicate clearly and often, with fluent written / verbal English
- Have a high level of attention to detail
- Enjoy providing a high level of service (fast, responsive, thoughtful, careful)
- Be comfortable working both independently and (as needed) together with a designer / frontend dev
- Be self-motivated
- Have good problem-solving ability
- Be willing to sign an NDA
- Be available for occasional phone / video meetings between 10:00 and 17:00 UTC+11.

If you are interested in this project please reply with a cover letter and either a contact email or Skype ID. Please no agencies / recruiters.";Python
Hello I need twitter user name scrapper can you help?;Python
We are a crypto company acting looking to hire an Experienced AI specialist to help with Visual AI Building. We currently are looking for someone to join our team asap and help us grow. If you feel this is you please reach out with experience!;Artificial Intelligence
"We are seeking an experienced developer to help us extract user data from Amazon QuickSite and eliminate some data points. 

Responsibilities:
- Extraction of user data from Amazon Quicksight / Elimination  / Filtering 
- Experience with Amazon Web Services is a plus

Requirements:
- Strong experience in data extraction and filtering
- Proficiency in Python or any other relevant programming language
- Knowledge of Amazon Quicksight
- Ability to work with large data sets

We need someone who can ensure that the data is separated accurately and efficiently.
If you are an experienced developer with a strong background in data extraction and filtering, we would love to hear from you. Please include your relevant experience and portfolio when applying.";Data Extraction
Turn structured data in a JSON into openai embeddings to answer specific questions about the dataset by following a similar process as https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb;React
Need to scrape product catalog (medical supplies) Access and details will be provided Having access to existing proxy servers is a plus;Data Extraction
I am looking for an expert in Apache Spark + PySpark who can make me hands on in these technologies.;Apache Spark
We have a variety of needs to improve the efficiency of our online business and want to achieve that through AI. Main focus will be marketing and product development.;Data Analysis
"We are reaching out to find an experienced Power BI developer who can help us connect our Oracle NetSuite data to Power BI using an ODBC connection and create financial dashboards. We are looking for someone who has hands-on experience in setting up a Power BI Desktop on an AWS instance and configuring the gateway.

The project objective is to bring our financial data from Oracle NetSuite into Power BI, so we can have a better view of our financial performance and make informed business decisions. The dashboards should include financial report like revenue analysis, vendor analysis, customer analysis, item analysis, income statement report, and profit-loss statement report, etc. The data should be updated every 15 minutes, and we expect the dashboards to be visually appealing, easy to use, and interactive.

The ideal candidate should have:

-Extensive experience in Power BI Desktop and Power BI Service.
-Hands-on experience with connecting Power BI to Oracle NetSuite using ODBC.
-Knowledge of AWS instance setup and Power BI gateway configuration.
-Ability to create financial dashboards with interactive visualizations and data insights.
-Strong communication skills and attention to detail.

If you have the necessary skills and experience and are interested in this project, please respond with your portfolio and references. We look forward to hearing from you soon.";Data Visualization
"We need a research analyst to help us find information about key partners in our target market.  The two types of partners we want to know more about are (1) U.S. National Retail Insurance and (2) MSPs (managed service providers) that provide cyber security services. 

Here is a more comprehensive write-up of our requirements, plus the templates to be populate for final deliverables. 

https://d2ai.notion.site/Market-Research-Project-a6f2f0ca8da24011bd5d3ae039f392bb";Market Analysis
"Hey Data Guru, 

We've built an application on top of MongoDB and are working on creating highly configurable analytics.

I'm looking for someone who has lot of experience in MongoDB as well as staging data for analytics purposes. 

One of our key constraints is that we can add new data fields on the fly and need to be able to use those fields in visualizations. 

If you have great experience building analytics platforms and with the MongoDB platform, let me know. 

We've got a development team that can do the work, but we need an expert coach to guide them and help us make the best decisions. 

Looking forward to hearing from you. 

John";MongoDB
"We're looking for a hardworking freelancer to help in extracting lead info from relevant websites. 
This simply involves visiting a website, locating contact info, and inputting this contact info into a google sheet. 
When applying, please include the word ""green"" and any relevant experience with data extraction.";Data Scraping
"Real-time multiple detection-recognition and counting of destroyed or demolished buildings after an earthquake. I already have a finished python project with human and object detection and counting of them. Python project will be provided in order to make the necessary changes.

The total changes that I want to be made are the following points:

1) Create and add the following classes with designated icons. Each class will be detected and counted (see pdf)
a) Demolished Buildings (Red box, 75% transparent)
b) Heavily Damaged Buildings (Orange box, 75% transparent)
c) Medium Damaged Buildings (Yellow box, 75% transparent)
d) Light Damaged Buildings (Green box, 75% transparent)

2) The menu bar must go from right side to left side. (see image_1)

3) At the menu bar:
a. Expanding menu bar with the following categories.
i. Fire (classes: humans, smoke, fire, cars, ems and fire brigade vehicles)
ii. Water (classes: humans, boats, smoke, fire)
iii. Earthquake level 1 ( SEE POINT 1)
iv. Earthquake level 2 (humans, smoke, fire, cars, ems and fire brigade vehicles)
v. General (humans, cars)
b. Activate button before each super category and each sub class. So, when a class is not active will not be detected and counted. Each class must work and independently and with others. For example, activation of category Earthquake level 1 and only class fire from Fire category.
c. If its possible change all the icons with modern ones.

4) Up left corner, the disaster monitoring logo, I want to be changed with image that I will provide.

It will run with a downloaded video from the computer from a predefined path or live from a social media link (youtube or other) as before.

Earthquake drone footage videos, extra details and material will be provided.";Python
I need a Google Analytics expert. My Google Analytics is a mess after a so called web developer attempted to set up the GA4 version of GA for me. I have 7 websites I would like to track performance with the present version and the new GA4 version of GA.  I need someone that clean up the account so I can make sense of it.;Google Analytics
Looking for an enterprise data architect who's experienced in architecting Power BI environments that connect with multiple disparate systems. Financial services/banking experience is a huge plus. Management consulting experience is a huge plus.;Microsoft Power BI
"We need someone to crawl the web for specific companies and products, which we will provide. Roughly 50-100 companies and a couple hundred products. 

The information we need is time sensitive, so needs to collected only for specific time periods which will vary for each company and product.

We only want strictly ethical crawling. No blackhat stuff please.

We prefer the work be done using Python.

This is a POC project for a client so will initially be on a small scale. If successful it could be expanded indefinitely.";Data Scraping
"Looking for an experienced developer for a long-term project, preferably full-time resource. You will work with a team for this project. This contract includes multiple sub-projects. Must be experienced with Datascience, ML Algorithms, Neural Network, Python and/or Tensorflow, AWS or GCP, must have very good knowledge at Computer Vision. We have specifications available for applicants to review upon request.

Required Experience:
Experience in computer vision projects
Image and video processing
Edge AI is a plus
Writing model based on requirement using DNN
Deploying models to cloud and integration
Python, R and/or TensorFlow programming languages";Data Science
"We want to build an AI trained model which learns to be the perfect virtual store assistant. Each model should also learn the prices and descriptions, info, meta data etc, just through Shopify API data if possible.

We want to build an app so that merchants can download it. It will be a great work together.";Python
I am looking for someone to work to perform a number of web scraping projects. For this particular project I am looking for someone that can scrape the attached Facebook company links and exact the company name, email, address/location, website and phone number.;Data Extraction
"We need to combine roughly 300 excel spreadsheets housing one data set with a second set of documents that contains a second, corresponding data point into one large aggregated spreadsheet, ideally via Excel power query.

The first document contains a set of excel documents associated to store locations. Each store is given a number, with 3 documents corresponding to that store. The second set of documents also refers to a store number, but outlines a set of codes that correspond to coordinates. The intention is to combine both sets of data so that we're able to highlight which of the profiles found in document one correspond with the coordinates in document two. 

We will need to add in additional columns to the aggregate document that references the store number, as well as the catchment radius (eg. 10km, 25km, 50km) so that we can pivot them appropriately and distinguish between them.";Data Processing
"We are looking for a Project-based Google Analytics/Tag Manager Specialist

Responsibilities

-Create measurement & tag implementation plan
-Audit Universal Analytics and GA4 implementation and create advice on this.
-Implement GA4 tracking on websites and mobile apps
-Configure and set up GA4 reports and dashboards
-Implement and maintain tags using Google Tag Manager
-Analyze and interpret data to drive business decisions
-Collaborate with cross-functional teams to identify and track key metrics

Requirements

-Proven experience with GA4 and GTM implementation
-Strong analytical skills and data interpretation experience
-Knowledge of HTML, CSS, and JavaScript
-Excellent communication and presentation skills
-Experience with Data studio";Data Analytics
display IoT device telemetry onto a dashboard.  The real-time data visualizations need to be fluid, animated display showing inter-dependent mixed parameters for Cloud dashboard as a compelling and attractive UI.  4-8 years experience within budget rate only pls;Graphic Design
"LOOKING FOR A TECHNICAL CO FOUNDER.

Need an AI / ML / NLP developer to develop our product. This product will be a completely custom chatbot and frontend/backend paired with a google extension. UIUX experience is nice to have as well but not required.

Please reach out if you are open to equity agreements.";Chatbot Development
"Hi, 

I run a small tech recruiting company. We are looking for an expert with GA4 who can do:

- configuration
- report creation
- dashboard creation 

We are looking to provide metrics and have someone that really knows Google Analytics well be able to extract the right information from GA4 for us.

Thanks,

Gino";Data Analytics
"I'm searching for a collaborator to work with on a weekly basis. To begin with, all the necessary preparations have been made. Your task will be to perform a series of A/B tests.

If you are interested in applying, please let me know how you would approach an A/B test on a website pop-up that does not have an attributed URL. It would be great to hear about your past experience in similar projects. Looking forward to hearing from you";A/B Testing
need help in understanding databricks, setting up a cluster, migrating data from json into parquet in s3 and being able to query tables. Also need to build a pipeline from postgres and mongo db to s3 using databricks;Databricks
"Second Chance Evaluation- Data Dashboard Scope of Work

This public health project serves to improve public health among Colorado’s youth by decreasing youth tobacco-related disparities, reducing youth initiation of tobacco, and decreasing youth tobacco use prevalence through evidence-based youth-focused strategies designed to increase knowledge of the dangers of youth tobacco use/resources to reduce youth tobacco use behaviors.  This will be accomplished by a multi-pronged approach: 1) promotion of comprehensive Tobacco Free Schools policies; 2) recruit/enroll students in the Second Chance program - an alternative, educational resource to punitive consequences for youth tobacco/nicotine violations – to youth at-risk of tobacco/nicotine use; 3) provide training in Tobacco Free Schools Policy.

Tobacco use remains the most preventable cause of death, disability and disease in Colorado, killing more than 5000 Coloradans each year.  Tobacco use is higher among the following populations: 1) Adults with lower income/education level; 2) Young adults aged 18-24 who go to work rather than college; 3) Black/African American and American Indian/Alaska Native adults; 4) Pregnant women who are on Medicaid; 5) Adults with mental health conditions; 6) LGBT youth/adults.  Youth use of vaping devices continues to increase, with 25.9% of Colorado high school youth reporting use of vaping devices.
 
This project promotes tobacco community-based work as identified by the Tobacco Education, Prevention and Cessation Program created by Colorado Revised Statutes 25-3.5-804 that supports funding for community-based and statewide tobacco education programs designed to reduce initiation of tobacco use by children/youth, promote cessation of tobacco use among youth/young adults, and reduce exposure to secondhand smoke/vapor.

Data Dashboard
The data dashboard will allow for the visualization of Second Chance data to track implementation in districts, schools, and counties in Colorado.

The dashboard will use five datasets: the Second Chance Administrator Report, the Second Chance Student Summary Report, RMC Health Learning Community Webinar Survey, RMC Health Training Survey, and Second Chance Technical Assistance (may also need to use data from Post-Training Surveys and Second Chance Administrator Satisfaction Survey). Using the dashboard, the client should be able to see:
1)	How many Second Chance administrators were approved throughout the year. Need to be able to filter by quarter, county, district, school, health statistic region, disparity data. Also need a map to visualize where administrators located.
2)	How many Second Chance administrators enrolled throughout the year. Need to be able to filter by quarter, county, district, school, health statistic region, disparity data.
3)	How many Second Chance administrators enrolled students in Second Chance throughout the year. Need to be able to filter by quarter, county, district, school, health statistic region, disparity data. Also need to show job categories for who referred adolescent with percentage breakdown of job position. Also need a map to visualize where administrators located.
4)	How many students were enrolled in Second Chance throughout the year. Need to be able to filter by quarter, county, district, school, health statistic region, disparity data. Should show also show percentage breakdown by grade. Also need a map to visualize where students were enrolled.
5)	How many students completed Second Chance throughout the year. Need to be able to filter by quarter, county, district, school, health statistic region, disparity data. Also need a map to visualize locations.
6)	Bar graphs showing key information from Second Chance Summary Report comparing pre-and-post surveys. 
7)	Maps
8)	Changes as a result of the training
9)	Information about the facilitators
10)	Possible, but may not have all data collected
11)	Possible, but may not have data collected

Skills:
•	1-2 years’ experience with Tableau.
•	Good communication skills.  Ability to secure needs, ask questions, and provide regular progress on the project.
•	Ability to work independently

Further details in the attached file.";Data Visualization
We are seeking a highly skilled and experienced professional to develop a Power BI dashboard for our HR Key Performance Indicators (KPIs). The ideal candidate should have a strong background in data analysis, data visualization, and Power BI development.;Microsoft Power BI
Need to install CUDA and CUDNN successfully and then I will install pytorch . Then, we need to check if my code is able to use the GPU while running the application or not.;CUDA
"A.I. Tensorflow, Convolutional neural networks (CNN) strategy.

Let's have a call to discuss more. I need to make videos.";Computer Vision
"Have stock market data for 2010 to 2015 with 5 different inputs including opening price, volume traded and oil price, but want rapid miner to predict 2016 daily opening price and produce a set of outputs;

- Weightings
- Graph showing 2016 actual and 2016 prediction
- Ability to try different machine learning methods (random forest or gradient boosted trees).";Data Science
"We are a very busy US digital agency, and are looking for a seasoned Conversion Rate Optimization (CRO) expert to work on several clients' high-traffic, high-profile Shopify stores immediately, and on an ongoing basis.

We are looking for a true CRO Expert, who understands all the moving parts, quantitative and qualitative, and can both audit/troubleshoot Shopify stores to identify specific issues within the flows, and implement/execute changes needed to optimize and improve conversion at each stage of the checkout funnel.

Our clients' Shopify stores are large, and successful, each doing 7+ figures per month in USD revenue, with 1MM+ monthly visitors. Maximizing the value of every visitor is key, and optimization matters. An improvement of 0.001% in completed checkouts can result in an extra six figures of revenue per month. 

We need a resource who is not intimidated operating at this level and can add solid value out of the gate. For that person, we can offer a very lucrative engagement immediately with opportunities for long-term relationship with our agency, and many of the brands we represent. 

Rather than continue to describe it here, we will leave it to the qualified bidders to explain and demonstrate expertise and competency. For the right person reading this, you know exactly what we are looking for.

Please submit a cover letter, demonstrating that you read and understood this post, and explaining how you will bring value, and please include several recent examples of success performing this service for other clients. Ideally, we are most interested in examples where you have been successful solving unusual or complex challenges.

This is an immediate opening, with lucrative, long-term potential for the right professional.";A/B Testing
Hello! I'm looking for someone who can complete a series of python questions that are fairly straightforward. This individual must use Jupyter Notebook to complete the task. The task includes three questions with multiple parts and needs to be completed by Feb. 17th.;Data Science
